---
title: Neural networks made easy (Part 79): Feature Aggregated Queries (FAQ) in the context of state
url: https://www.mql5.com/en/articles/14394
categories: Trading Systems, Expert Advisors, Machine Learning
relevance_score: 3
scraped_at: 2026-01-23T19:12:59.054266
---

[![](https://www.mql5.com/ff/sh/0hvxp984jjj79943z2/6373d9e5710a718ffa6a7d50a5db9dd1.jpg)\\
Web terminal on your iPhone or Android\\
\\
Full-featured MetaTrader 5 platform for any devices and web browsers\\
\\
Learn more](https://www.mql5.com/ff/go?link=https://trade.metatrader5.com/&a=uyigsjnbfcdvysiynusmriwvhincciwd&s=c95531ae2fd8a81b0fac3def2e4cf820a67584bbf4b02f76ec75f808942dbbd2&uid=&ref=https://www.mql5.com/en/articles/14394&id=bfogggabsofabcpxuzmgaibarmaxasdrj&fz_uniq=5070105307255869449)

MetaTrader 5 / Trading systems


### Introduction

Most of the methods we discussed earlier analyze the state of the environment as something static, which fully corresponds to the definition of a Markov process. Naturally, we filled the description of the environment state with historical data to provide the model with as much necessary information as possible. But the model does not evaluate the dynamics of changes in states. This also refers to the method presented in the previous article: [DFFT](https://www.mql5.com/en/articles/14338) was developed for detecting objects in static images.

However, observations of price movements indicate that the dynamics of changes can sometimes indicate the strength and direction of the upcoming movement with sufficient probability. Logically, we now turn our attention to methods for detecting objects in video.

Object detection in video has a number of certain characteristics and must solve the problem of changes in object features caused by motion, which are not encountered in the image domain. One of the solutions is to use temporal information and combine features from adjacent frames. The paper " [FAQ: Feature Aggregated Queries for Transformer-based Video Object Detectors](https://www.mql5.com/go?link=https://arxiv.org/abs/2303.08319 "https://arxiv.org/abs/2303.08319")" proposes a new approach to detecting objects in video. The authors of the article improve the quality of queries for Transformer-based models by aggregating them. To achieve this goal, a practical method is proposed to generate and aggregate queries according to the features of the input frames. Extensive experimental results provided in the paper validate the effectiveness of the proposed method. The proposed approaches can be extended to a wide range of methods for detecting objects in images and videos to improve their efficiency.

### 1\. Feature Aggregated Queries Algorithm

The _FAQ_ method is not the first to use the _Transformer_ architecture to detect objects in video. However, existing video object detectors using _Transformer_ improve the representation of object features by aggregating Queries.Â The naive vanilla idea is to average _Queries_Â from neighboring frames. _Queries_Â are initialized randomly and used during the training process. Neighboring _Queries_ are aggregated into Î”ğ‘¸ for the current frame ğ‘° and are represented as:

![](https://c.mql5.com/2/71/5445160019434.png)

Where _w_ are learnable weighs for aggregation.

The simple idea of creating learnable weights is based on the cosine similarity of the features of the input frame. Following existing video object detectors, the authors of the FAQ method generate aggregation weights using the formula:

![](https://c.mql5.com/2/71/128991879551.png)

Where Î±, Î² are mapping functions, and \|â‹…\| denotes normalization.

Relevant features of the current frame ğ‘° and its neighboring ğ‘°_i_ are denoted as ğ‘­ and ğ‘­ _i_. As a result, the probability of identifying an object can be expressed as:

![](https://c.mql5.com/2/71/4483852122852.png)

Where ğ‘· _v_ is the predicted probability using aggregated queries Î”ğ‘¸ _v_.

There is an issue in the vanilla query aggregation module: these neighboring queries ğ‘¸i are initialized randomly and are not associated with their corresponding frames ğ‘° _i_. Therefore, neighboring queries ğ‘¸ _i_ do not provide enough temporal or semantic information to overcome performance degradation issues caused by fast motion. Although the weights _wi_ used for aggregation are related to the functions ğ‘­ and ğ‘­ _i_, there are not enough constraints on the number of these randomly initiated queries. Therefore, the authors of the _FAQ_ method suggest updating the aggregation module _Query_ to a dynamic version that adds constraints to queries and can adjust weights according to neighboring frames. The simple implementation idea is to generate queries ğ‘¸ _i_ directly from the features ğ‘­ _i_ of the input frame. However, experiments conducted by the authors of the method show that this method is difficult to train and always generates worse results. In contrast to the naive idea mentioned above, the authors of the method propose to generate new queries, adaptive to the original data, from the randomly initialized _Queries_. First, we define two types of Query vectors: basic and dynamic. During the learning and operating processes, dynamic _Queries_ are generated from basic _Queries_ in accordance with the features ğ‘­ _i_, ğ‘­ of input frames as:

![](https://c.mql5.com/2/71/5542284384075.png)

Where _M_ is a mapping function for building a relationship of the base query _Qb_ with dynamic _Qd_ in accordance with the features ğ‘­ and ğ‘­ _i_.

First, let's split the basic queries into groups according to _r_ queries. Then, for each group, we use the same weights ğ‘½ to determine the weighted average query in the current group:

![](https://c.mql5.com/2/71/5217364826202.png)

To build a relationship between dynamic queries ğ‘¸ _d_ and the corresponding frame ğ‘° _i_, the authors of the method propose to generate weights ğ‘½ using global features:

![](https://c.mql5.com/2/71/3823097368864.png)

Where _A_ is a global pooling operation to change the dimension of the feature tensor and create global-level features,

_G_ is a mapping function that allows you to project global features into the dimension of the dynamic tensor _Query_.

Thus, the process of dynamic query aggregation based on the source data features can be updated as follows:

![](https://c.mql5.com/2/71/4102098266301.png)

During training, the authors of the method propose to aggregate both dynamic queries and basic ones. Both types of queries are aggregated with the same weights and corresponding predictions ğ‘· _d_ and ğ‘· _b_ are generated. Here we also calculate the two-way agreement error for both predictions. The hyperparameter Î³ is used to balance the effect of errors.

![](https://c.mql5.com/2/71/1557368289944.png)

During operation, we use only dynamic queries ğ‘¸ _d_ and their corresponding predictions ğ‘· _d_ as final results that only slightly complicate the original models.

Below is the [authors'](https://www.mql5.com/go?link=https://arxiv.org/abs/2303.08319 "https://arxiv.org/abs/2303.08319") visualization of the method.

![Authors' visualization of the FAQ method](https://c.mql5.com/2/71/f23z1i.png)

### 2\. Implementation using MQL5

We have considered the theoretical aspects of the algorithms. Now, let us move on to the practical part of our article, in which we will implement the proposed approaches using MQL5.

As can be seen from the above description of the _FAQ_ method, its main contribution is the creation of a module for generating and aggregating the dynamic query tensor in the _Transformer_ Decoder. I would like to remind you that the authors of the [DFFT](https://www.mql5.com/en/articles/14338) method excluded the decoder due to its ineffectiveness. Well, in the current work we will add a Decoder and will evaluate its effectiveness in the context of using dynamic _Query_ entities proposed by the authors of the _FAQ_ method.

#### 2.1 Dynamic Query Class

To generate dynamic queries, we will create a new class _CNeuronFAQOCL_. The new object will inherit from the neural layer base class _CNeuronBaseOCL_.

```
class CNeuronFAQOCLÂ Â : public CNeuronBaseOCL
Â Â {
protected:
Â Â  //---
Â Â  CNeuronConvOCLÂ Â Â Â    cF;
Â Â  CNeuronBaseOCLÂ Â Â Â    cWv;
Â Â  CNeuronBatchNormOCL  cNormV;
Â Â  CNeuronBaseOCLÂ Â Â Â    cQd;
Â Â  CNeuronXCiTOCLÂ Â Â Â    cDQd;
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â feedForward(CNeuronBaseOCL *NeuronOCL);
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â updateInputWeights(CNeuronBaseOCL *NeuronOCL);

public:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  CNeuronFAQOCL(void) {};
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ~CNeuronFAQOCL(void) {};
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint window, uint window_out, uint heads,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint units_count, uint input_units,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ENUM_OPTIMIZATION optimization_type,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint batch);
Â Â  virtual boolÂ Â Â Â Â Â calcInputGradients(CNeuronBaseOCL *prevLayer);
Â Â  //---
Â Â  virtual intÂ Â Â Â Â Â  Type(void)Â Â  constÂ Â  {Â Â return defNeuronFAQOCL;Â Â  }
Â Â  //--- methods for working with files
Â Â  virtual boolÂ Â Â Â Â Â Save(int const file_handle);
Â Â  virtual boolÂ Â Â Â Â Â Load(int const file_handle);
Â Â  virtual CLayerDescription* GetLayerInfo(void);
Â Â  virtual boolÂ Â Â Â Â Â WeightsUpdate(CNeuronBaseOCL *source, float tau);
Â Â  virtual voidÂ Â Â Â Â Â SetOpenCL(COpenCLMy *obj);
Â Â };
```

In the new method, in addition to the basic set of overridden methods, we will add 5 internal neural layers. We will explain their purposes during implementation. We declared all internal objects static, which allows us to leave the constructor and destructor of the class empty.

A class object is initialized in the _CNeuronFAQOCL::Init_ method. In the method parameters, we get all the key parameters for initializing internal objects. In the body of the method, we call the relevant method of the parent class. As you already know, this method implements the minimum necessary control of the received parameters and initialization of inherited objects.

```
bool CNeuronFAQOCL::Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  uint window, uint window_out, uint heads,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  uint units_count, uint input_units,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ENUM_OPTIMIZATION optimization_type, uint batch)
Â Â {
Â Â  if(!CNeuronBaseOCL::Init(numOutputs, myIndex, open_cl, window * units_count,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â optimization_type, batch))
Â Â Â Â Â Â return false;
```

There is no activation function specified for our class.

```
Â Â  activation = None;
```

Next, we initialize the internal objects. Here we turn to the approaches to generating dynamic _Queries_ proposed by the authors of the _Query_ method. To generate aggregation weights for the base _Queries_ based on the features of the source data, let's create 3 layers. First, we pass the features of the source data through a convolutional layer, in which we analyze the patterns of neighboring environmental states.

```
Â Â  if(!cF.Init(0, 0, OpenCL, 3 * window, window, 8, fmax((int)input_units - 2, 1), optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  cF.SetActivationFunction(None);
```

To increase the stability of the model training and operation processes, we normalize the received data.

```
Â Â  if(!cNormV.Init(8, 1, OpenCL, fmax((int)input_units - 2, 1) * 8, batch, optimization_type))
Â Â Â Â Â Â return false;
Â Â  cNormV.SetActivationFunction(None);
```

Then we will compress the data to the size of the weight tensor of basic query aggregation. To ensure that the resulting weights are in the range \[0,1\], we use a sigmoid activation function.

```
Â Â  if(!cWv.Init(units_count * window_out, 2, OpenCL, 8, optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  cWv.SetActivationFunction(SIGMOID);
```

According to the _FAQ_ algorithm, we have to multiply the resulting vector of aggregation coefficients by the matrix of basic _Queries_ which are randomly generated at the beginning of training. In my implementation, I decided to go a little further and train basic queries. Well, I haven't come up with anything better than using a fully connected neural layer. We feed the layer a vector of aggregation coefficients, while the weight matrix of the fully connected layer is a tensor of the basic queries being trained.

```
Â Â  if(!cQd.Init(0, 4, OpenCL, units_count * window_out, optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  cQd.SetActivationFunction(None);
```

Next comes the aggregation of dynamic _Queries_. _FAQ_ method authors in their paper present the results of experiments with various aggregation methods. The most effective was the dynamic _Query_ aggregation using the _Transformer_ architecture. Following the above results, we use the _CNeuronXCiTOCL_ class object for aggregating dynamic queries.

```
Â Â  if(!cDQd.Init(0, 5, OpenCL, window_out, 3, heads, units_count, 3, optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  cDQd.SetActivationFunction(None);
```

To eliminate unnecessary data copying operations, we replace the results buffers of our class and error gradients.

```
Â Â  if(Output != cDQd.getOutput())
Â Â Â Â  {
Â Â Â Â Â Â Output.BufferFree();
Â Â Â Â Â Â delete Output;
Â Â Â Â Â Â Output = cDQd.getOutput();
Â Â Â Â  }
Â Â  if(Gradient != cDQd.getGradient())
Â Â Â Â  {
Â Â Â Â Â Â Gradient.BufferFree();
Â Â Â Â Â Â delete Gradient;
Â Â Â Â Â Â Gradient = cDQd.getGradient();
Â Â Â Â  }
//---
Â Â  return true;
Â Â }
```

After initializing the object, we move on to organizing the feed-forward process in the _CNeuronFAQOCL::feedForward_ method. Everything here is quite simple and straightforward. In the method parameters, we receive a pointer to the source data layer with parameters for describing the state of the environment. In the body of the method, we alternately call the relevant feed-forward methods for internal objects.

```
bool CNeuronFAQOCL::feedForward(CNeuronBaseOCL *NeuronOCL)
Â Â {
//---
Â Â  if(!cF.FeedForward(NeuronOCL))
Â Â Â Â Â Â return false;
```

We first transfer the description of the environment through a convolutional layer and normalize the resulting data.

```
Â Â  if(!cNormV.FeedForward(GetPointer(cF)))
Â Â Â Â Â Â return false;
```

Then we generate aggregation coefficients of the base _Queries_.

```
Â Â  if(!cWv.FeedForward(GetPointer(cNormV)))
Â Â Â Â Â Â return false;
```

Creating dynamic _Queries_.

```
Â Â  if(!cQd.FeedForward(GetPointer(cWv)))
Â Â Â Â Â Â return false;
```

Aggregating them in the _CNeuronXCiTOCL_ class object.

```
Â Â  if(!cDQd.FeedForward(GetPointer(cQd)))
Â Â Â Â Â Â return false;
//---
Â Â  return true;
Â Â }
```

Since we have the substitution of data buffers, the results of the internal layer _cDQd_ are reflected in the results buffer of our _CNeuronFAQOCL_ class without unnecessary copying operations. Therefore, we can complete the method.

Next, we create the backpropagation methods _CNeuronFAQOCL::calcInputGradients_ and _CNeuronFAQOCL::updateInputWeights_. Similar to the feed-forward method, here we call the relevant methods on internal objects, but in reverse order. Therefore, we will not consider in detail their algorithm in this article. You can study the complete code of all methods of the dynamic query generation class _CNeuronFAQOCL_ using the attchments to the article.

#### 2.2 Cross-Attention Class

The next step is to create a Cross-Attention class. Earlier, within the framework of the implementation of the _ADAPT_ method, we already created a cross-attention layer [_CNeuronMH2AttentionOCL_](https://www.mql5.com/en/articles/14143#para31). However, that time we analyzed the relationships between different dimensions of one tensor. Now the task is a little different. We need to evaluate the dependencies of the generated dynamic _Queries_ from the _CNeuronFAQOCL_ class to the compressed state of the environment from the Encoder of our model. In other words, we need to evaluate the relationship between 2 different tensors.

To implement this functionality we will create a new class _CNeuronCrossAttention_, which will inherit part of the necessary functionality from the _CNeuronMH2AttentionOCL_ class mentioned above.

```
class CNeuronCrossAttention : public CNeuronMH2AttentionOCL
Â Â {
protected:
Â Â  uintÂ Â Â Â Â Â Â Â Â Â Â Â Â Â iWindow_K;
Â Â  uintÂ Â Â Â Â Â Â Â Â Â Â Â Â Â iUnits_K;
Â Â  CNeuronBaseOCLÂ Â Â Â *cContext;
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â feedForward(CNeuronBaseOCL *NeuronOCL, CNeuronBaseOCL *Context);
Â Â  virtual boolÂ Â Â Â Â Â feedForward(CNeuronBaseOCL *NeuronOCL, CBufferFloat *Context);
Â Â  virtual boolÂ Â Â Â Â Â attentionOut(void);
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â updateInputWeights(CNeuronBaseOCL *NeuronOCL, CNeuronBaseOCL *Context);
Â Â  virtual boolÂ Â Â Â Â Â AttentionInsideGradients(void);

public:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  CNeuronCrossAttention(void) {};
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ~CNeuronCrossAttention(void) { delete cContext; }
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint window, uint window_key, uint heads,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint units_count, uint window_k, uint units_k,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ENUM_OPTIMIZATION optimization_type,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint batch);
Â Â  virtual boolÂ Â Â Â Â Â calcInputGradients(CNeuronBaseOCL *prevLayer, CNeuronBaseOCL *Context);
Â Â  virtual boolÂ Â Â Â Â Â calcInputGradients(CNeuronBaseOCL *prevLayer, CBufferFloat *SecondInput,
                                        CBufferFloat *SecondGradient, ENUM_ACTIVATION SecondActivation = None);
Â Â  virtual boolÂ Â Â Â Â Â updateInputWeights(CNeuronBaseOCL *NeuronOCL, CBufferFloat *Context);
Â Â  //---
Â Â  virtual intÂ Â Â Â Â Â  Type(void)Â Â  constÂ Â  {Â Â return defNeuronCrossAttenOCL;Â Â  }
Â Â  //--- methods for working with files
Â Â  virtual boolÂ Â Â Â Â Â Save(int const file_handle);
Â Â  virtual boolÂ Â Â Â Â Â Load(int const file_handle);
Â Â  virtual CLayerDescription* GetLayerInfo(void);
Â Â };
```

In addition to the standard set of overridden methods, you can notice 2 new variables here:

- iWindow\_K â€” the size of the description vector for one element of the 2nd tensor;
- iUnits\_K â€” the number of elements in the sequence of of the 2nd tensor.

Additionally, we will add a dynamic pointer to the auxiliary neural layer _cContext_, which will be initialized as a source object if necessary. Since this object performs an optional auxiliary role, the constructor of our class remains empty. But in the class destructor, we need to delete the dynamic object.

```
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ~CNeuronCrossAttention(void) { delete cContext; }
```

As usual, the object is initialized in the _CNeuronCrossAttention::Init_ method. In the method parameters, we obtain the necessary data about the architecture of the created layer. In the body of the method, we call the relevant method of the base neural layer class _CNeuronBaseOCL::Init_.

```
bool CNeuronCrossAttention::Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  uint window, uint window_key, uint heads,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  uint units_count, uint window_k, uint units_k,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  ENUM_OPTIMIZATION optimization_type,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  uint batch)
Â Â {
Â Â  if(!CNeuronBaseOCL::Init(numOutputs, myIndex, open_cl, window * units_count,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â optimization_type, batch))
Â Â Â Â Â Â return false;
```

Please note that we are calling the initialization method not of the direct parent class _CNeuronMH2AttentionOCL_, but of the base class _CNeuronBaseOCL_. This is due to differences in the architectures of the _CNeuronCrossAttention_ and _CNeuronMH2AttentionOCL_ classes. Therefore, further in the body of the method we initialize not only new, but also inherited objects.

First, we save our layer settings.

```
Â Â  iWindow = fmax(window, 1);
Â Â  iWindowKey = fmax(window_key, 1);
Â Â  iUnits = fmax(units_count, 1);
Â Â  iWindow_K = fmax(window_k, 1);
Â Â  iUnits_K = fmax(units_k, 1);
Â Â  iHeads = fmax(heads, 1);
Â Â  activation = None;
```

Next we initialize the _Query_ entity generation layer.

```
Â Â  if(!Q_Embedding.Init(0, 0, OpenCL, iWindow, iWindow, iWindowKey * iHeads, iUnits, optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  Q_Embedding.SetActivationFunction(None);
```

Perform the same for the _Key_ and _Value_ entities.

```
Â Â  if(!KV_Embedding.Init(0, 0, OpenCL, iWindow_K, iWindow_K, 2 * iWindowKey * iHeads, iUnits_K, optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  KV_Embedding.SetActivationFunction(None);
```

Please do not confuse the _Query_ entities generated here with dynamic queries generated in the _CNeuronFAQOCL_ class.

As part of the implementation of the FAQ method, we will input the generated dynamic queries into this class as initial data. We can say here that the _Q\_Embedding_ layer distributes them among attention heads. And the _KV\_Embedding_ layer generates entities from a compressed representation of the environmental state received from the Encoder.

But let's return to our class initialization method. After initializing the entity generation layers, we will create a dependency coefficient matrix buffer _Score_.

```
Â Â  ScoreIndex = OpenCL.AddBuffer(sizeof(float) * iUnits * iUnits_K * iHeads, CL_MEM_READ_WRITE);
Â Â  if(ScoreIndex == INVALID_HANDLE)
Â Â Â Â Â Â return false;
```

Here we also create a layer of the multiheaded attention results.

```
Â Â  if(!MHAttentionOut.Init(0, 0, OpenCL, iWindowKey * iUnits * iHeads, optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  MHAttentionOut.SetActivationFunction(None);
```

And a layer of aggregation of attention heads.

```
Â Â  if(!W0.Init(0, 0, OpenCL, iWindowKey * iHeads, iWindowKey * iHeads, iWindow, iUnits, optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  W0.SetActivationFunction(None);
Â Â  if(!AttentionOut.Init(0, 0, OpenCL, iWindow * iUnits, optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  AttentionOut.SetActivationFunction(None);
```

Next comes the _FeedForward_ block.

```
Â Â  if(!FF[0].Init(0, 0, OpenCL, iWindow, iWindow, 4 * iWindow, iUnits, optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  if(!FF[1].Init(0, 0, OpenCL, 4 * iWindow, 4 * iWindow, iWindow, iUnits, optimization_type, batch))
Â Â Â Â Â Â return false;
Â Â  for(int i = 0; i < 2; i++)
Â Â Â Â Â Â FF[i].SetActivationFunction(None);
```

At the end of the initialization method, we organize the substitution of buffers.

```
Â Â  Gradient.BufferFree();
Â Â  delete Gradient;
Â Â  Gradient = FF[1].getGradient();
//---
Â Â  return true;
Â Â }
```

After initializing the class, we, as usual, proceed to organizing the feed-forward pass. Within this class, we will not create new kernels on the _OpenCL_ program side. In this case, we will use kernels created to implement processes of the parent class. However, we need to make some minor adjustments to the methods for calling the kernels. For example, in the _CNeuronCrossAttention::attentionOut_ method, we will only change the arrays indicating the task space and local groups in terms of the size of the _Key_ entity sequence (highlighted in the code in red).

```
bool CNeuronCrossAttention::attentionOut(void)
Â Â {
Â Â  if(!OpenCL)
Â Â Â Â Â Â return false;
//---
Â Â  uint global_work_offset[3] = {0};
Â Â  uint global_work_size[3] = {iUnits/*Q units*/, iUnits_K/*K units*/, iHeads};
Â Â  uint local_work_size[3] = {1, iUnits_K, 1};
Â Â  ResetLastError();
Â Â  if(!OpenCL.SetArgumentBuffer(def_k_MH2AttentionOut, def_k_mh2ao_q, Q_Embedding.getOutputIndex()))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.SetArgumentBuffer(def_k_MH2AttentionOut, def_k_mh2ao_kv, KV_Embedding.getOutputIndex()))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.SetArgumentBuffer(def_k_MH2AttentionOut, def_k_mh2ao_score, ScoreIndex))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.SetArgumentBuffer(def_k_MH2AttentionOut, def_k_mh2ao_out, MHAttentionOut.getOutputIndex()))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.SetArgument(def_k_MH2AttentionOut, def_k_mh2ao_dimension, (int)iWindowKey))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.Execute(def_k_MH2AttentionOut, 3, global_work_offset, global_work_size, local_work_size))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of execution kernel %s: %d", __FUNCTION__, GetLastError());
Â Â Â Â Â Â return false;
Â Â Â Â  }
//---
Â Â  return true;
Â Â }
```

The entire feed-forward algorithm is described at the top level, in the _CNeuronCrossAttention::feedForward_ method. Unlike the relevant method of the parent class, this method receives pointers to 2 objects of neural layers in its parameters. They contain the data of 2 tensors for dependence analysis.

```
bool CNeuronCrossAttention::feedForward(CNeuronBaseOCL *NeuronOCL, CNeuronBaseOCL *Context)
Â Â {
//---
Â Â  if(!Q_Embedding.FeedForward(NeuronOCL))
Â Â Â Â Â Â return false;
//---
Â Â  if(!KV_Embedding.FeedForward(Context))
Â Â Â Â Â Â return false;
```

In the method body, we first generate entities from the received data. Then we call the multi-head attention method.

```
Â Â  if(!attentionOut())
Â Â Â Â Â Â return false;
```

We aggregate the results of attention.

```
Â Â  if(!W0.FeedForward(GetPointer(MHAttentionOut)))
Â Â Â Â Â Â return false;
```

And sum them up with the source data. After that we normalize the result within the elements of the sequence. In the context of the _FAQ_ method implementation, normalization will be performed in the context of individual dynamic queries.

```
Â Â  if(!SumAndNormilize(W0.getOutput(), NeuronOCL.getOutput(), AttentionOut.getOutput(), iWindow))
Â Â Â Â Â Â return false;
```

The data then passes through the _FeedForward_ block.

```
Â Â  if(!FF[0].FeedForward(GetPointer(AttentionOut)))
Â Â Â Â Â Â return false;
Â Â  if(!FF[1].FeedForward(GetPointer(FF[0])))
Â Â Â Â Â Â return false;
```

Then we sum up and normalize the data again.

```
Â Â  if(!SumAndNormilize(FF[1].getOutput(), AttentionOut.getOutput(), Output, iWindow))
Â Â Â Â Â Â return false;
//---
Â Â  return true;
Â Â }
```

After successfully completing all of the above operations, we terminate the method.

With this, we complete the description of the feed-forward method and move on to organizing the backpropagation pass. Here we also use the kernel created as part of the implementation of the parent class and make specific changes to the kernel call method _CNeuronCrossAttention::AttentionInsideGradients_.

```
bool CNeuronCrossAttention::AttentionInsideGradients(void)
Â Â {
Â Â  if(!OpenCL)
Â Â Â Â Â Â return false;
//---
Â Â  uint global_work_offset[3] = {0};
Â Â  uint global_work_size[3] = {iUnits, iWindowKey, iHeads};
Â Â  ResetLastError();
Â Â  if(!OpenCL.SetArgumentBuffer(def_k_MH2AttentionInsideGradients, def_k_mh2aig_q, Q_Embedding.getOutputIndex()))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.SetArgumentBuffer(def_k_MH2AttentionInsideGradients, def_k_mh2aig_qg, Q_Embedding.getGradientIndex()))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.SetArgumentBuffer(def_k_MH2AttentionInsideGradients, def_k_mh2aig_kv, KV_Embedding.getOutputIndex()))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.SetArgumentBuffer(def_k_MH2AttentionInsideGradients, def_k_mh2aig_kvg, KV_Embedding.getGradientIndex()))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.SetArgumentBuffer(def_k_MH2AttentionInsideGradients, def_k_mh2aig_score, ScoreIndex))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.SetArgumentBuffer(def_k_MH2AttentionInsideGradients, def_k_mh2aig_outg, MHAttentionOut.getGradientIndex()))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.SetArgument(def_k_MH2AttentionInsideGradients, def_k_mh2aig_kunits, (int)iUnits_K))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of set parameter kernel %s: %d; line %d", __FUNCTION__, GetLastError(), __LINE__);
Â Â Â Â Â Â return false;
Â Â Â Â  }
Â Â  if(!OpenCL.Execute(def_k_MH2AttentionInsideGradients, 3, global_work_offset, global_work_size))
Â Â Â Â  {
Â Â Â Â Â Â printf("Error of execution kernel %s: %d", __FUNCTION__, GetLastError());
Â Â Â Â Â Â return false;
Â Â Â Â  }
//---
Â Â  return true;
Â Â }
```

The process of propagating the error gradient through our cross-attention layer is implemented in the _CNeuronCrossAttention::calcInputGradients_ method. Like to the feed-forward method, in parameters to this method we pass pointers to 2 layers with 2 data threads.

```
bool CNeuronCrossAttention::calcInputGradients(CNeuronBaseOCL *prevLayer, CNeuronBaseOCL *Context)
Â Â {
Â Â  if(!FF[1].calcInputGradients(GetPointer(FF[0])))
Â Â Â Â Â Â return false;
Â Â  if(!FF[0].calcInputGradients(GetPointer(AttentionOut)))
Â Â Â Â Â Â return false;
```

Thanks to the substitution of data buffers, the error gradient obtained from the subsequent layer is immediately propagated to the error gradient buffer of the 2nd layer of the _FeedForward_ block. Therefore, we don't need to copy the data. Next, we immediately call the methods for distributing the error gradient of the internal layers of the _FeedForward_ block.

At this stage, we have to add the error gradient received from the block _FeedForward_ and from the subsequent neural layer.

```
Â Â  if(!SumAndNormilize(FF[1].getGradient(), AttentionOut.getGradient(), W0.getGradient(), iWindow, false))
Â Â Â Â Â Â return false;
```

Next, we distribute the error gradient across the attention heads.

```
Â Â  if(!W0.calcInputGradients(GetPointer(MHAttentionOut)))
Â Â Â Â Â Â return false;
```

Call the method to propagate the error gradient to the _Query_, _Key_ and _Value_ entities.

```
Â Â  if(!AttentionInsideGradients())
Â Â Â Â Â Â return false;
```

The gradient from the _Key_ and _Value_ entities is transferred to the Context (Encoder) layer.

```
Â Â  if(!KV_Embedding.calcInputGradients(Context))
Â Â Â Â Â Â return false;
```

The gradient from _Query_ is transfered to the previous layer.

```
Â Â  if(!Q_Embedding.calcInputGradients(prevLayer))
Â Â Â Â Â Â return false;
```

Do not forget to sum up the error gradients.

```
Â Â  if(!SumAndNormilize(prevLayer.getGradient(), W0.getGradient(), prevLayer.getGradient(), iWindow, false))
Â Â Â Â Â Â return false;
//---
Â Â  return true;
Â Â }
```

Then we complete the method.

The _CNeuronCrossAttention::updateInputWeights_ method for updating internal object parameters is pretty simple. It just calls the relevant methods on internal objects one by one. You can find them in the attachment. Also, the attachment contains the required file operation methods. In addition, it contains the complete code of all programs and classes used in this article.

With this, we complete the creation of new classes and move on to describing the model architecture.

#### 2.3 Model architecture

The architecture of the models is presented in the _CreateDescriptions_ method. The current architecture of the models is largely copied from the implementation of the [DFFT](https://www.mql5.com/en/articles/14338#para32) method. However, we have added a Decoder. Therefore, the Actor and Critic receive data from the Decoder. Thus, to create a description of the models, we need 4 dynamic arrays.

```
bool CreateDescriptions(CArrayObj *dot, CArrayObj *decoder, CArrayObj *actor, CArrayObj *critic)
Â Â {
//---
Â Â  CLayerDescription *descr;
//---
Â Â  if(!dot)
Â Â Â Â  {
Â Â Â Â Â Â dot = new CArrayObj();
Â Â Â Â Â Â if(!dot)
Â Â Â Â Â Â Â Â  return false;
Â Â Â Â  }
Â Â  if(!decoder)
Â Â Â Â  {
Â Â Â Â Â Â decoder = new CArrayObj();
Â Â Â Â Â Â if(!decoder)
Â Â Â Â Â Â Â Â  return false;
Â Â Â Â  }
Â Â  if(!actor)
Â Â Â Â  {
Â Â Â Â Â Â actor = new CArrayObj();
Â Â Â Â Â Â if(!actor)
Â Â Â Â Â Â Â Â  return false;
Â Â Â Â  }
Â Â  if(!critic)
Â Â Â Â  {
Â Â Â Â Â Â critic = new CArrayObj();
Â Â Â Â Â Â if(!critic)
Â Â Â Â Â Â Â Â  return false;
Â Â Â Â  }
```

The Encoder model (dot) has been copied from the previous article without changes. You can find its detailed description [here](https://www.mql5.com/en/articles/14338#para32).

The Decoder uses the latent data of the Encoder at the level of the positional encoding layer as input data.

```
//--- Decoder
Â Â  decoder.Clear();
//--- Input layer
Â Â  CLayerDescription *po = dot.At(LatentLayer);
Â Â  if(!po || !(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.type = defNeuronBaseOCL;
Â Â  descr.count = po.count * po.window;
Â Â  descr.activation = None;
Â Â  descr.optimization = ADAM;
Â Â  if(!decoder.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
```

Let me remind you that at this level, we remove embeddings of several environmental states stored in the local stack with added positional encoding labels. Actually, these embeddings contain a sequence of signs describing the state of the environment for _GPTBars_ candlesticks. This can be compared to the frames of the video series. Based on this data, we generate dynamic _Queries_.

```
//--- layer 1
Â Â  if(!(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.type = defNeuronFAQOCL;
Â Â Â Â  {
Â Â Â Â Â Â int temp[] = {QueryCount, po.count};
Â Â Â Â Â Â ArrayCopy(descr.units, temp);
Â Â Â Â  }
Â Â  descr.window = po.window;
Â Â  descr.window_out = 16;
Â Â  descr.optimization = ADAM;
Â Â  descr.step = 4;
Â Â  descr.activation = None;
Â Â  if(!decoder.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
```

And implement Cross-Attention.

```
//--- layer 2
Â Â  CLayerDescription *encoder = dot.At(dot.Total() - 1);
Â Â  if(!encoder || !(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.type = defNeuronCrossAttenOCL;
Â Â Â Â  {
Â Â Â Â Â Â int temp[] = {QueryCount, encoder.count};
Â Â Â Â Â Â ArrayCopy(descr.units, temp);
Â Â Â Â  }
Â Â Â Â  {
Â Â Â Â Â Â int temp[] = {16, encoder.window};
Â Â Â Â Â Â ArrayCopy(descr.windows, temp);
Â Â Â Â  }
Â Â  descr.window_out = 16;
Â Â  descr.step = 4;
Â Â  descr.activation = None;
Â Â  descr.optimization = ADAM;
Â Â  if(!decoder.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
```

The Actor receives data from the Decoder.

```
//--- Actor
Â Â  actor.Clear();
//--- Input layer
Â Â  encoder = decoder.At(decoder.Total() - 1);
Â Â  if(!encoder || !(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.type = defNeuronBaseOCL;
Â Â  prev_count = descr.count = encoder.units[0] * encoder.windows[0];
Â Â  descr.activation = None;
Â Â  descr.optimization = ADAM;
Â Â  if(!actor.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
```

And combines it with the description of the account status.

```
//--- layer 1
Â Â  if(!(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.type = defNeuronConcatenate;
Â Â  descr.count = LatentCount;
Â Â  descr.window = prev_count;
Â Â  descr.step = AccountDescr;
Â Â  descr.optimization = ADAM;
Â Â  descr.activation = SIGMOID;
Â Â  if(!actor.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
```

After that, the data passes through 2 fully connected layers.

```
//--- layer 2
Â Â  if(!(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.type = defNeuronBaseOCL;
Â Â  descr.count = LatentCount;
Â Â  descr.activation = SIGMOID;
Â Â  descr.optimization = ADAM;
Â Â  if(!actor.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
//--- layer 3
Â Â  if(!(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.type = defNeuronBaseOCL;
Â Â  descr.count = 2 * NActions;
Â Â  descr.activation = None;
Â Â  descr.optimization = ADAM;
Â Â  if(!actor.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
```

At the output, we add stochasticity to the Actor's policy.

```
//--- layer 4
Â Â  if(!(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.type = defNeuronVAEOCL;
Â Â  descr.count = NActions;
Â Â  descr.optimization = ADAM;
Â Â  if(!actor.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
```

The critic model has been copied almost as is. The only change is that the source of initial data has been changed from Encoder to Decoder.

```
//--- Critic
Â Â  critic.Clear();
//--- Input layer
Â Â  if(!(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.Copy(actor.At(0));
Â Â  if(!critic.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
//--- layer 1
Â Â  if(!(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.Copy(actor.At(1));
Â Â  descr.step = NActions;
Â Â  descr.optimization = ADAM;
Â Â  descr.activation = SIGMOID;
Â Â  if(!critic.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
//--- layer 2
Â Â  if(!(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.type = defNeuronBaseOCL;
Â Â  descr.count = LatentCount;
Â Â  descr.activation = SIGMOID;
Â Â  descr.optimization = ADAM;
Â Â  if(!critic.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
//--- layer 3
Â Â  if(!(descr = new CLayerDescription()))
Â Â Â Â Â Â return false;
Â Â  descr.type = defNeuronBaseOCL;
Â Â  descr.count = NRewards;
Â Â  descr.activation = None;
Â Â  descr.optimization = ADAM;
Â Â  if(!critic.Add(descr))
Â Â Â Â  {
Â Â Â Â Â Â delete descr;
Â Â Â Â Â Â return false;
Â Â Â Â  }
//---
Â Â  return true;
Â Â }
```

#### 2.4 Environmental Interaction EAs

When preparing this article, I used 3 environmental interaction EAs:

- Research.mq5
- ResearchRealORL.mq5
- Test.mq5

EA "...\\Experts\\FAQ\\ResearchRealORL.mq5" is not linked to the model architecture. Since all the EAs are trained and tested by analyzing the same initial data that describes the environment, this EA is used in different articles without any chnages. You can find a full description of its code and use approaches [here](https://www.mql5.com/en/articles/13854).

In the code of the EA "...\\Experts\\FAQ\\Research.mq5", we add a Decoder model.

```
CNetÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  DOT;
CNetÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  Decoder;
CNetÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  Actor;
```

Accordingly, in the initialization method, we add loading of this model and, if necessary, initializing it with random parameters.

```
//+------------------------------------------------------------------+
//| Expert initialization functionÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  |
//+------------------------------------------------------------------+
int OnInit()
Â Â {
//---
........
........
//--- load models
Â Â  float temp;
//---
Â Â  if(!DOT.Load(FileName + "DOT.nnw", temp, temp, temp, dtStudied, true) ||
Â Â Â Â Â Â !Actor.Load(FileName + "Act.nnw", temp, temp, temp, dtStudied, true))
Â Â Â Â  {
Â Â Â Â Â Â CArrayObj *dot = new CArrayObj();
Â Â Â Â Â Â CArrayObj *decoder = new CArrayObj();
Â Â Â Â Â Â CArrayObj *actor = new CArrayObj();
Â Â Â Â Â Â CArrayObj *critic = new CArrayObj();
Â Â Â Â Â Â if(!CreateDescriptions(dot, decoder, actor, critic))
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  delete dot;
Â Â Â Â Â Â Â Â  delete decoder;
Â Â Â Â Â Â Â Â  delete actor;
Â Â Â Â Â Â Â Â  delete critic;
Â Â Â Â Â Â Â Â  return INIT_FAILED;
Â Â Â Â Â Â Â Â }
Â Â Â Â Â Â if(!DOT.Create(dot) ||
Â Â Â Â Â Â Â Â  !Decoder.Create(decoder) ||
Â Â Â Â Â Â Â Â  !Actor.Create(actor))
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  delete dot;
Â Â Â Â Â Â Â Â  delete decoder;
Â Â Â Â Â Â Â Â  delete actor;
Â Â Â Â Â Â Â Â  delete critic;
Â Â Â Â Â Â Â Â  return INIT_FAILED;
Â Â Â Â Â Â Â Â }
Â Â Â Â Â Â delete dot;
Â Â Â Â Â Â delete decoder;
Â Â Â Â Â Â delete actor;
Â Â Â Â Â Â delete critic;
Â Â Â Â  }
//---
Â Â  Decoder.SetOpenCL(DOT.GetOpenCL());
Â Â  Actor.SetOpenCL(DOT.GetOpenCL());
//---
........
........
//---
Â Â  return(INIT_SUCCEEDED);
Â Â }
```

Please note that in this case we are not using the Critic model. Its functionality is not involved in the process of interacting with the environment and collecting data for training.

The actual process of interaction with the environment is organized in the OnTick method. In the method body, we first check the occurrence of a new bar opening event.

```
//+------------------------------------------------------------------+
//| Expert tick functionÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  |
//+------------------------------------------------------------------+
void OnTick()
Â Â {
//---
Â Â  if(!IsNewBar())
Â Â Â Â Â Â return;
```

The entire process is based on the analysis of closed candles.

When a required event occurs, we first download historical data.

```
Â Â  int bars = CopyRates(Symb.Name(), TimeFrame, iTime(Symb.Name(), TimeFrame, 1), HistoryBars, Rates);
Â Â  if(!ArraySetAsSeries(Rates, true))
Â Â Â Â Â Â return;
//---
Â Â  RSI.Refresh();
Â Â  CCI.Refresh();
Â Â  ATR.Refresh();
Â Â  MACD.Refresh();
Â Â  Symb.Refresh();
Â Â  Symb.RefreshRates();
```

We transfer the data to the buffer describing the current state of the environment.

```
Â Â  float atr = 0;
Â Â  for(int b = 0; b < (int)HistoryBars; b++)
Â Â Â Â  {
Â Â Â Â Â Â float open = (float)Rates[b].open;
Â Â Â Â Â Â float rsi = (float)RSI.Main(b);
Â Â Â Â Â Â float cci = (float)CCI.Main(b);
Â Â Â Â Â Â atr = (float)ATR.Main(b);
Â Â Â Â Â Â float macd = (float)MACD.Main(b);
Â Â Â Â Â Â float sign = (float)MACD.Signal(b);
Â Â Â Â Â Â if(rsi == EMPTY_VALUE || cci == EMPTY_VALUE || atr == EMPTY_VALUE || macd == EMPTY_VALUE || sign == EMPTY_VALUE)
Â Â Â Â Â Â Â Â  continue;
Â Â Â Â Â Â //---
Â Â Â Â Â Â int shift = b * BarDescr;
Â Â Â Â Â Â sState.state[shift] = (float)(Rates[b].close - open);
Â Â Â Â Â Â sState.state[shift + 1] = (float)(Rates[b].high - open);
Â Â Â Â Â Â sState.state[shift + 2] = (float)(Rates[b].low - open);
Â Â Â Â Â Â sState.state[shift + 3] = (float)(Rates[b].tick_volume / 1000.0f);
Â Â Â Â Â Â sState.state[shift + 4] = rsi;
Â Â Â Â Â Â sState.state[shift + 5] = cci;
Â Â Â Â Â Â sState.state[shift + 6] = atr;
Â Â Â Â Â Â sState.state[shift + 7] = macd;
Â Â Â Â Â Â sState.state[shift + 8] = sign;
Â Â Â Â  }
Â Â  bState.AssignArray(sState.state);
```

Then we collect data on the account status and open positions.

```
Â Â  sState.account[0] = (float)AccountInfoDouble(ACCOUNT_BALANCE);
Â Â  sState.account[1] = (float)AccountInfoDouble(ACCOUNT_EQUITY);
//---
Â Â  double buy_value = 0, sell_value = 0, buy_profit = 0, sell_profit = 0;
Â Â  double position_discount = 0;
Â Â  double multiplyer = 1.0 / (60.0 * 60.0 * 10.0);
Â Â  int total = PositionsTotal();
Â Â  datetime current = TimeCurrent();
Â Â  for(int i = 0; i < total; i++)
Â Â Â Â  {
Â Â Â Â Â Â if(PositionGetSymbol(i) != Symb.Name())
Â Â Â Â Â Â Â Â  continue;
Â Â Â Â Â Â double profit = PositionGetDouble(POSITION_PROFIT);
Â Â Â Â Â Â switch((int)PositionGetInteger(POSITION_TYPE))
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  case POSITION_TYPE_BUY:
Â Â Â Â Â Â Â Â Â Â Â Â buy_value += PositionGetDouble(POSITION_VOLUME);
Â Â Â Â Â Â Â Â Â Â Â Â buy_profit += profit;
Â Â Â Â Â Â Â Â Â Â Â Â break;
Â Â Â Â Â Â Â Â  case POSITION_TYPE_SELL:
Â Â Â Â Â Â Â Â Â Â Â Â sell_value += PositionGetDouble(POSITION_VOLUME);
Â Â Â Â Â Â Â Â Â Â Â Â sell_profit += profit;
Â Â Â Â Â Â Â Â Â Â Â Â break;
Â Â Â Â Â Â Â Â }
Â Â Â Â Â Â position_discount += profit - (current - PositionGetInteger(POSITION_TIME)) * multiplyer * MathAbs(profit);
Â Â Â Â  }
Â Â  sState.account[2] = (float)buy_value;
Â Â  sState.account[3] = (float)sell_value;
Â Â  sState.account[4] = (float)buy_profit;
Â Â  sState.account[5] = (float)sell_profit;
Â Â  sState.account[6] = (float)position_discount;
Â Â  sState.account[7] = (float)Rates[0].time;
```

The received data is grouped into the account status buffer.

```
Â Â  bAccount.Clear();
Â Â  bAccount.Add((float)((sState.account[0] - PrevBalance) / PrevBalance));
Â Â  bAccount.Add((float)(sState.account[1] / PrevBalance));
Â Â  bAccount.Add((float)((sState.account[1] - PrevEquity) / PrevEquity));
Â Â  bAccount.Add(sState.account[2]);
Â Â  bAccount.Add(sState.account[3]);
Â Â  bAccount.Add((float)(sState.account[4] / PrevBalance));
Â Â  bAccount.Add((float)(sState.account[5] / PrevBalance));
Â Â  bAccount.Add((float)(sState.account[6] / PrevBalance));
```

We also add the timestamp harmonics here.

```
Â Â  double x = (double)Rates[0].time / (double)(D'2024.01.01' - D'2023.01.01');
Â Â  bAccount.Add((float)MathSin(2.0 * M_PI * x));
Â Â  x = (double)Rates[0].time / (double)PeriodSeconds(PERIOD_MN1);
Â Â  bAccount.Add((float)MathCos(2.0 * M_PI * x));
Â Â  x = (double)Rates[0].time / (double)PeriodSeconds(PERIOD_W1);
Â Â  bAccount.Add((float)MathSin(2.0 * M_PI * x));
Â Â  x = (double)Rates[0].time / (double)PeriodSeconds(PERIOD_D1);
Â Â  bAccount.Add((float)MathSin(2.0 * M_PI * x));
```

The collected data is first fed to the Encoder input.

```
Â Â  if(bAccount.GetIndex() >= 0)
Â Â Â Â Â Â if(!bAccount.BufferWrite())
Â Â Â Â Â Â Â Â  return;
//---
Â Â  if(!DOT.feedForward((CBufferFloat*)GetPointer(bState), 1, false, (CBufferFloat*)NULL))
Â Â Â Â  {
Â Â Â Â Â Â PrintFormat("%s -> %d", __FUNCTION__, __LINE__);
Â Â Â Â Â Â return;
Â Â Â Â  }
```

The Encoder operation results are transferred to the Decoder.

```
Â Â  if(!Decoder.feedForward((CNet*)GetPointer(DOT), LatentLayer,(CNet*)GetPointer(DOT)))
Â Â Â Â  {
Â Â Â Â Â Â PrintFormat("%s -> %d", __FUNCTION__, __LINE__);
Â Â Â Â Â Â return;
Â Â Â Â  }
```

Then they are transferred to the Actor.

```
//--- Actor
Â Â  if(!Actor.feedForward((CNet *)GetPointer(Decoder), -1, (CBufferFloat*)GetPointer(bAccount)))
Â Â Â Â  {
Â Â Â Â Â Â PrintFormat("%s -> %d", __FUNCTION__, __LINE__);
Â Â Â Â Â Â return;
Â Â Â Â  }
//---
Â Â  PrevBalance = sState.account[0];
Â Â  PrevEquity = sState.account[1];
```

We load the actions predicted by the Actor, and exclude counter operations.

```
Â Â  vector<float> temp;
Â Â  Actor.getResults(temp);
Â Â  if(temp.Size() < NActions)
Â Â Â Â Â Â temp = vector<float>::Zeros(NActions);
//---
Â Â  double min_lot = Symb.LotsMin();
Â Â  double step_lot = Symb.LotsStep();
Â Â  double stops = MathMax(Symb.StopsLevel(), 1) * Symb.Point();
Â Â  if(temp[0] >= temp[3])
Â Â Â Â  {
Â Â Â Â Â Â temp[0] -= temp[3];
Â Â Â Â Â Â temp[3] = 0;
Â Â Â Â  }
Â Â  else
Â Â Â Â  {
Â Â Â Â Â Â temp[3] -= temp[0];
Â Â Â Â Â Â temp[0] = 0;
Â Â Â Â  }
```

Then we decode the forecast actions and perform the necessary trading actions. First we implement long positions.

```
//--- buy control
Â Â  if(temp[0] < min_lot || (temp[1] * MaxTP * Symb.Point()) <= stops || (temp[2] * MaxSL * Symb.Point()) <= stops)
Â Â Â Â  {
Â Â Â Â Â Â if(buy_value > 0)
Â Â Â Â Â Â Â Â  CloseByDirection(POSITION_TYPE_BUY);
Â Â Â Â  }
Â Â  else
Â Â Â Â  {
Â Â Â Â Â Â double buy_lot = min_lot + MathRound((double)(temp[0] - min_lot) / step_lot) * step_lot;
Â Â Â Â Â Â double buy_tp = NormalizeDouble(Symb.Ask() + temp[1] * MaxTP * Symb.Point(), Symb.Digits());
Â Â Â Â Â Â double buy_sl = NormalizeDouble(Symb.Ask() - temp[2] * MaxSL * Symb.Point(), Symb.Digits());
Â Â Â Â Â Â if(buy_value > 0)
Â Â Â Â Â Â Â Â  TrailPosition(POSITION_TYPE_BUY, buy_sl, buy_tp);
Â Â Â Â Â Â if(buy_value != buy_lot)
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  if(buy_value > buy_lot)
Â Â Â Â Â Â Â Â Â Â Â Â ClosePartial(POSITION_TYPE_BUY, buy_value - buy_lot);
Â Â Â Â Â Â Â Â  else
Â Â Â Â Â Â Â Â Â Â Â Â Trade.Buy(buy_lot - buy_value, Symb.Name(), Symb.Ask(), buy_sl, buy_tp);
Â Â Â Â Â Â Â Â }
Â Â Â Â  }
```

Then Short positions.

```
//--- sell control
Â Â  if(temp[3] < min_lot || (temp[4] * MaxTP * Symb.Point()) <= stops || (temp[5] * MaxSL * Symb.Point()) <= stops)
Â Â Â Â  {
Â Â Â Â Â Â if(sell_value > 0)
Â Â Â Â Â Â Â Â  CloseByDirection(POSITION_TYPE_SELL);
Â Â Â Â  }
Â Â  else
Â Â Â Â  {
Â Â Â Â Â Â double sell_lot = min_lot + MathRound((double)(temp[3] - min_lot) / step_lot) * step_lot;;
Â Â Â Â Â Â double sell_tp = NormalizeDouble(Symb.Bid() - temp[4] * MaxTP * Symb.Point(), Symb.Digits());
Â Â Â Â Â Â double sell_sl = NormalizeDouble(Symb.Bid() + temp[5] * MaxSL * Symb.Point(), Symb.Digits());
Â Â Â Â Â Â if(sell_value > 0)
Â Â Â Â Â Â Â Â  TrailPosition(POSITION_TYPE_SELL, sell_sl, sell_tp);
Â Â Â Â Â Â if(sell_value != sell_lot)
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  if(sell_value > sell_lot)
Â Â Â Â Â Â Â Â Â Â Â Â ClosePartial(POSITION_TYPE_SELL, sell_value - sell_lot);
Â Â Â Â Â Â Â Â  else
Â Â Â Â Â Â Â Â Â Â Â Â Trade.Sell(sell_lot - sell_value, Symb.Name(), Symb.Bid(), sell_sl, sell_tp);
Â Â Â Â Â Â Â Â }
Â Â Â Â  }
```

At the end of the method, we save the results of interaction with the environment into the experience replay buffer.

```
Â Â  sState.rewards[0] = bAccount[0];
Â Â  sState.rewards[1] = 1.0f - bAccount[1];
Â Â  if((buy_value + sell_value) == 0)
Â Â Â Â Â Â sState.rewards[2] -= (float)(atr / PrevBalance);
Â Â  else
Â Â Â Â Â Â sState.rewards[2] = 0;
Â Â  for(ulong i = 0; i < NActions; i++)
Â Â Â Â Â Â sState.action[i] = temp[i];
Â Â  if(!Base.Add(sState))
Â Â Â Â Â Â ExpertRemove();
Â Â }
```

The rest of the EA's methods have not undergone any changes.

Similar changes have been made to the EA "...\\Experts\\FAQ\\Test.mq5. You can study the full code of both EAs yourself using the codes from the attachment.

#### 2.5 Model training EA

The models are trained in the "...\\Experts\\FAQ\\Study.mq5" EA. As with previously developed EAs, the structure of the EA is copied from previous works. In accordance with changes in the model architecture, we add a Decoder.

```
CNetÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  DOT;
CNetÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  Decoder;
CNetÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  Actor;
CNetÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  Critic;
```

As you can see, the Critic also participates in the model training process.

In the EA initialization method, we first load the training data.

```
//+------------------------------------------------------------------+
//| Expert initialization functionÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  |
//+------------------------------------------------------------------+
int OnInit()
Â Â {
//---
Â Â  ResetLastError();
Â Â  if(!LoadTotalBase())
Â Â Â Â  {
Â Â Â Â Â Â PrintFormat("Error of load study data: %d", GetLastError());
Â Â Â Â Â Â return INIT_FAILED;
Â Â Â Â  }
```

Then we try to load the pre-trained models. If we cannot load the models, then we create new models and initialize them with random parameters.

```
//--- load models
Â Â  float temp;
Â Â  if(!DOT.Load(FileName + "DOT.nnw", temp, temp, temp, dtStudied, true) ||
Â Â Â Â Â Â !Decoder.Load(FileName + "Dec.nnw", temp, temp, temp, dtStudied, true) ||
Â Â Â Â Â Â !Actor.Load(FileName + "Act.nnw", temp, temp, temp, dtStudied, true) ||
Â Â Â Â Â Â !Critic.Load(FileName + "Crt.nnw", temp, temp, temp, dtStudied, true)
Â Â Â Â  )
Â Â Â Â  {
Â Â Â Â Â Â CArrayObj *dot = new CArrayObj();
Â Â Â Â Â Â CArrayObj *decoder = new CArrayObj();
Â Â Â Â Â Â CArrayObj *actor = new CArrayObj();
Â Â Â Â Â Â CArrayObj *critic = new CArrayObj();
Â Â Â Â Â Â if(!CreateDescriptions(dot, decoder, actor, critic))
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  delete dot;
Â Â Â Â Â Â Â Â  delete decoder;
Â Â Â Â Â Â Â Â  delete actor;
Â Â Â Â Â Â Â Â  delete critic;
Â Â Â Â Â Â Â Â  return INIT_FAILED;
Â Â Â Â Â Â Â Â }
Â Â Â Â Â Â if(!DOT.Create(dot) ||
Â Â Â Â Â Â Â Â  !Decoder.Create(decoder) ||
Â Â Â Â Â Â Â Â  !Actor.Create(actor) ||
Â Â Â Â Â Â Â Â  !Critic.Create(critic))
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  delete dot;
Â Â Â Â Â Â Â Â  delete decoder;
Â Â Â Â Â Â Â Â  delete actor;
Â Â Â Â Â Â Â Â  delete critic;
Â Â Â Â Â Â Â Â  return INIT_FAILED;
Â Â Â Â Â Â Â Â }
Â Â Â Â Â Â delete dot;
Â Â Â Â Â Â delete decoder;
Â Â Â Â Â Â delete actor;
Â Â Â Â Â Â delete critic;
Â Â Â Â  }
```

We transfer all models into one _OpenCL_ context.

```
Â Â  OpenCL = DOT.GetOpenCL();
Â Â  Decoder.SetOpenCL(OpenCL);
Â Â  Actor.SetOpenCL(OpenCL);
Â Â  Critic.SetOpenCL(OpenCL);
```

We implement minimal control over the compliance of the model architecture.

```
Â Â  Actor.getResults(Result);
Â Â  if(Result.Total() != NActions)
Â Â Â Â  {
Â Â Â Â Â Â PrintFormat("The scope of the actor does not match the actions count (%d <> %d)", NActions, Result.Total());
Â Â Â Â Â Â return INIT_FAILED;
Â Â Â Â  }
//---
Â Â  DOT.GetLayerOutput(0, Result);
Â Â  if(Result.Total() != (HistoryBars * BarDescr))
Â Â Â Â  {
Â Â Â Â Â Â PrintFormat("Input size of Encoder doesn't match state description (%d <> %d)", Result.Total(), (HistoryBars * BarDescr));
Â Â Â Â Â Â return INIT_FAILED;
Â Â Â Â  }
```

We create auxiliary data buffers.

```
Â Â  if(!bGradient.BufferInit(MathMax(AccountDescr, NForecast), 0) ||
Â Â Â Â Â Â !bGradient.BufferCreate(OpenCL))
Â Â Â Â  {
Â Â Â Â Â Â PrintFormat("Error of create buffers: %d", GetLastError());
Â Â Â Â Â Â return INIT_FAILED;
Â Â Â Â  }
```

Generate a custom event for the start of the learning process.

```
Â Â  if(!EventChartCustom(ChartID(), 1, 0, 0, "Init"))
Â Â Â Â  {
Â Â Â Â Â Â PrintFormat("Error of create study event: %d", GetLastError());
Â Â Â Â Â Â return INIT_FAILED;
Â Â Â Â  }
//---
Â Â  return(INIT_SUCCEEDED);
Â Â }
```

In the EA deinitialization method, we save the trained models and clear the memory of dynamic objects.

```
//+------------------------------------------------------------------+
//| Expert deinitialization functionÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  |
//+------------------------------------------------------------------+
void OnDeinit(const int reason)
Â Â {
//---
Â Â  if(!(reason == REASON_INITFAILED || reason == REASON_RECOMPILE))
Â Â Â Â  {
Â Â Â Â Â Â Actor.Save(FileName + "Act.nnw", 0, 0, 0, TimeCurrent(), true);
Â Â Â Â Â Â DOT.Save(FileName + "DOT.nnw", 0, 0, 0, TimeCurrent(), true);
Â Â Â Â Â Â Decoder.Save(FileName + "Dec.nnw", 0, 0, 0, TimeCurrent(), true);
Â Â Â Â Â Â Critic.Save(FileName + "Crt.nnw", 0, 0, 0, TimeCurrent(), true);
Â Â Â Â  }
Â Â  delete Result;
Â Â  delete OpenCL;
Â Â }
```

The process of training models is implemented in the Train method. In the body of the method, we first determine the probability of choosing trajectories in accordance with their profitability.

```
//+------------------------------------------------------------------+
//| Train functionÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  |
//+------------------------------------------------------------------+
void Train(void)
Â Â {
//---
Â Â  vector<float> probability = GetProbTrajectories(Buffer, 0.9);
```

Then we declare local variables.

```
Â Â  vector<float> result, target;
Â Â  bool Stop = false;
//---
Â Â  uint ticks = GetTickCount();
```

Then we create a system of nested loops for the learning process.

The Encoder architecture provides an Embedding layer with an internal buffer for accumulating historical data. This kind of architectural solution is very sensitive to the historical sequence of the source data received. Therefore, to train models, we organize a system of nested loops. The outer loop counts the number of training batches. In a nested loop within the training batch, the initial data is fed in historical chronology.

In the body of the outer loop, we sample a trajectory and the state to start the training batch.

```
Â Â  for(int iter = 0; (iter < Iterations && !IsStopped() && !Stop); iter ++)
Â Â Â Â  {
Â Â Â Â Â Â int tr = SampleTrajectory(probability);
Â Â Â Â Â Â int batch = GPTBars + 48;
Â Â Â Â Â Â int state = (int)((MathRand() * MathRand() / MathPow(32767, 2)) * (Buffer[tr].Total - 2 - PrecoderBars - batch));
Â Â Â Â Â Â if(state <= 0)
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  iter--;
Â Â Â Â Â Â Â Â  continue;
Â Â Â Â Â Â Â Â }
```

Clearing the internal buffer used for the accumulation of historical data.

```
Â Â Â Â Â Â DOT.Clear();
```

Determining the state of the end of the training package.

```
Â Â Â Â Â Â int end = MathMin(state + batch, Buffer[tr].Total - PrecoderBars);
```

Then we organize a nested learning loop. In its body, we first load a historical description of the environment state from the experience replay buffer.

```
Â Â Â Â Â Â for(int i = state; i < end; i++)
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  bState.AssignArray(Buffer[tr].States[i].state);
```

With the available data, we run a feed-forward pass through the Encoder and Decoder.

```
Â Â Â Â Â Â Â Â  //--- Trajectory
Â Â Â Â Â Â Â Â  if(!DOT.feedForward((CBufferFloat*)GetPointer(bState), 1, false, (CBufferFloat*)NULL))
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â PrintFormat("%s -> %d", __FUNCTION__, __LINE__);
Â Â Â Â Â Â Â Â Â Â Â Â Stop = true;
Â Â Â Â Â Â Â Â Â Â Â Â break;
Â Â Â Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â Â  if(!Decoder.feedForward((CNet*)GetPointer(DOT), LatentLayer, (CNet*)GetPointer(DOT)))
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â PrintFormat("%s -> %d", __FUNCTION__, __LINE__);
Â Â Â Â Â Â Â Â Â Â Â Â Stop = true;
Â Â Â Â Â Â Â Â Â Â Â Â break;
Â Â Â Â Â Â Â Â Â Â  }
```

We also load the corresponding description of the account state from the experience replay buffer and transfer the data to the appropriate buffer

```
Â Â Â Â Â Â Â Â  //--- Policy
Â Â Â Â Â Â Â Â  float PrevBalance = Buffer[tr].States[MathMax(i - 1, 0)].account[0];
Â Â Â Â Â Â Â Â  float PrevEquity = Buffer[tr].States[MathMax(i - 1, 0)].account[1];
Â Â Â Â Â Â Â Â  bAccount.Clear();
Â Â Â Â Â Â Â Â  bAccount.Add((Buffer[tr].States[i].account[0] - PrevBalance) / PrevBalance);
Â Â Â Â Â Â Â Â  bAccount.Add(Buffer[tr].States[i].account[1] / PrevBalance);
Â Â Â Â Â Â Â Â  bAccount.Add((Buffer[tr].States[i].account[1] - PrevEquity) / PrevEquity);
Â Â Â Â Â Â Â Â  bAccount.Add(Buffer[tr].States[i].account[2]);
Â Â Â Â Â Â Â Â  bAccount.Add(Buffer[tr].States[i].account[3]);
Â Â Â Â Â Â Â Â  bAccount.Add(Buffer[tr].States[i].account[4] / PrevBalance);
Â Â Â Â Â Â Â Â  bAccount.Add(Buffer[tr].States[i].account[5] / PrevBalance);
Â Â Â Â Â Â Â Â  bAccount.Add(Buffer[tr].States[i].account[6] / PrevBalance);
```

Adding the timestamp harmonics.

```
Â Â Â Â Â Â Â Â  double time = (double)Buffer[tr].States[i].account[7];
Â Â Â Â Â Â Â Â  double x = time / (double)(D'2024.01.01' - D'2023.01.01');
Â Â Â Â Â Â Â Â  bAccount.Add((float)MathSin(x != 0 ? 2.0 * M_PI * x : 0));
Â Â Â Â Â Â Â Â  x = time / (double)PeriodSeconds(PERIOD_MN1);
Â Â Â Â Â Â Â Â  bAccount.Add((float)MathCos(x != 0 ? 2.0 * M_PI * x : 0));
Â Â Â Â Â Â Â Â  x = time / (double)PeriodSeconds(PERIOD_W1);
Â Â Â Â Â Â Â Â  bAccount.Add((float)MathSin(x != 0 ? 2.0 * M_PI * x : 0));
Â Â Â Â Â Â Â Â  x = time / (double)PeriodSeconds(PERIOD_D1);
Â Â Â Â Â Â Â Â  bAccount.Add((float)MathSin(x != 0 ? 2.0 * M_PI * x : 0));
Â Â Â Â Â Â Â Â  if(bAccount.GetIndex() >= 0)
Â Â Â Â Â Â Â Â Â Â Â Â bAccount.BufferWrite();
```

The process completely repeats that of the EAs for interaction with the environment. However, we do not poll the terminal but load all the data from the experience replay buffer.

After receiving the data, we can perform a sequential feed-forward pass for the Actor and Critic.

```
Â Â Â Â Â Â Â Â  //--- Actor
Â Â Â Â Â Â Â Â  if(!Actor.feedForward((CNet *)GetPointer(Decoder), -1, (CBufferFloat*)GetPointer(bAccount)))
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â PrintFormat("%s -> %d", __FUNCTION__, __LINE__);
Â Â Â Â Â Â Â Â Â Â Â Â Stop = true;
Â Â Â Â Â Â Â Â Â Â Â Â break;
Â Â Â Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â Â  //--- Critic
Â Â Â Â Â Â Â Â  if(!Critic.feedForward((CNet *)GetPointer(Decoder), -1, (CNet*)GetPointer(Actor)))
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â PrintFormat("%s -> %d", __FUNCTION__, __LINE__);
Â Â Â Â Â Â Â Â Â Â Â Â Stop = true;
Â Â Â Â Â Â Â Â Â Â Â Â break;
Â Â Â Â Â Â Â Â Â Â  }
```

The feed-forward pass is followed by a backpropagation pass, during which the model parameters are optimized. First, we will perform a backpropagation pass of the Actor to minimize the error till the actions from the experience replay buffer.

```
Â Â Â Â Â Â Â Â  Result.AssignArray(Buffer[tr].States[i].action);
Â Â Â Â Â Â Â Â  if(!Actor.backProp(Result, (CBufferFloat *)GetPointer(bAccount), (CBufferFloat *)GetPointer(bGradient)) ||
```

The error gradient from the Actor is transfered to the Decoder.

```
Â Â Â Â Â Â Â Â Â Â Â Â !Decoder.backPropGradient((CNet *)GetPointer(DOT), -1, -1, false) ||
```

The Decoder, in turn, transmits the error gradient to the Encoder. Pay attention that the Decoder takes the initial data from 2 layers of the Encoder and transmits the error gradient to 2 corresponding layers. To correctly update the model parameters, we need to first propagate the gradient from the latent layer.

```
Â Â Â Â Â Â Â Â Â Â Â Â !DOT.backPropGradient((CBufferFloat*)NULL, (CBufferFloat*)NULL, LatentLayer) ||
```

And only then - through the entire Encoder model.

```
Â Â Â Â Â Â Â Â Â Â Â Â !DOT.backPropGradient((CBufferFloat*)NULL)
Â Â Â Â Â Â Â Â Â Â  )
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â PrintFormat("%s -> %d", __FUNCTION__, __LINE__);
Â Â Â Â Â Â Â Â Â Â Â Â Stop = true;
Â Â Â Â Â Â Â Â Â Â Â Â break;
Â Â Â Â Â Â Â Â Â Â  }
```

Next, we determine the reward for the upcoming transition.

```
Â Â Â Â Â Â Â Â  result.Assign(Buffer[tr].States[i + 1].rewards);
Â Â Â Â Â Â Â Â  target.Assign(Buffer[tr].States[i + 2].rewards);
Â Â Â Â Â Â Â Â  result = result - target * DiscFactor;
Â Â Â Â Â Â Â Â  Result.AssignArray(result);
```

And we optimize the Critic parameters with subsequent transmission of the error gradient to all participating models.

```
Â Â Â Â Â Â Â Â  if(!Critic.backProp(Result, (CNet *)GetPointer(Actor)) ||
Â Â Â Â Â Â Â Â Â Â Â Â !Decoder.backPropGradient((CNet *)GetPointer(DOT), -1, -1, false) ||
Â Â Â Â Â Â Â Â Â Â Â Â !DOT.backPropGradient((CBufferFloat*)NULL, (CBufferFloat*)NULL, LatentLayer) ||
Â Â Â Â Â Â Â Â Â Â Â Â !DOT.backPropGradient((CBufferFloat*)NULL) ||
Â Â Â Â Â Â Â Â Â Â Â Â !Actor.backPropGradient((CBufferFloat *)GetPointer(bAccount), (CBufferFloat *)GetPointer(bGradient), -1, false) ||
Â Â Â Â Â Â Â Â Â Â Â Â !Decoder.backPropGradient((CNet *)GetPointer(DOT), -1, -1, false) ||
Â Â Â Â Â Â Â Â Â Â Â Â !DOT.backPropGradient((CBufferFloat*)NULL, (CBufferFloat*)NULL, LatentLayer) ||
Â Â Â Â Â Â Â Â Â Â Â Â !DOT.backPropGradient((CBufferFloat*)NULL)
Â Â Â Â Â Â Â Â Â Â  )
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â PrintFormat("%s -> %d", __FUNCTION__, __LINE__);
Â Â Â Â Â Â Â Â Â Â Â Â Stop = true;
Â Â Â Â Â Â Â Â Â Â Â Â break;
Â Â Â Â Â Â Â Â Â Â  }
```

At the end of the operations within the loop system, we inform the user about the training progress and move on to the next iteration.

```
Â Â Â Â Â Â Â Â  if(GetTickCount() - ticks > 500)
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â double percent = (double(i - state) / ((end - state)) + iter) * 100.0 / (Iterations);
Â Â Â Â Â Â Â Â Â Â Â Â string str = StringFormat("%-14s %6.2f%% -> Error %15.8f\n", "Actor", percent, Actor.getRecentAverageError());
Â Â Â Â Â Â Â Â Â Â Â Â str += StringFormat("%-14s %6.2f%% -> Error %15.8f\n", "Critic", percent, Critic.getRecentAverageError());
Â Â Â Â Â Â Â Â Â Â Â Â Comment(str);
Â Â Â Â Â Â Â Â Â Â Â Â ticks = GetTickCount();
Â Â Â Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â Â }
Â Â Â Â  }
```

After successfully completing all iterations of the model training loop system, we clear the comments field on the chart.

```
Â Â  Comment("");
```

We also print model training results to the log and initiate EA termination.

```
Â Â  PrintFormat("%s -> %d -> %-15s %10.7f", __FUNCTION__, __LINE__, "Actor", Actor.getRecentAverageError());
Â Â  PrintFormat("%s -> %d -> %-15s %10.7f", __FUNCTION__, __LINE__, "Critic", Critic.getRecentAverageError());
Â Â  ExpertRemove();
//---
Â Â }
```

This concludes the description of the algorithms of the programs used. The full codes of these EAs are attached below. We now move on to the final part of the article, in which we will test the algorithm.

### 3\. Testing

In this article, we got acquainted with the Feature Aggregated Queries method and implemented its approaches using _MQL5_. Now it's time to evaluate the results of the work we have done. As always, I trained and tested my model on historical data of the EURUSD instrument with the H1 timeframe. The models are trained on a historical period for the first 7 months of 2023. To test the trained models, we use historical data from August 2023.

The model discussed in this article analyzes input data similar to the models from previous articles. The vectors of the Actor actions and rewards for completed transitions to a new state are also identical to the previous articles. Therefore, to train models, we can use the experience replay buffer collected while training the models from previous articles. For this, we rename the file to "FAQ.bd".

However, if you do not have a file from previous works or you want to create a new one for some reasons, I recommend first saving a few passes using the trade history of real signals. This was described in the article describing the [RealORL](https://www.mql5.com/en/articles/13854#para4) method.

Then you can supplement the experience replay buffer with random passes using the EA "...\\Experts\\FAQ\\Research.mq5". For this, run slow optimization of this EA in the MetaTrader 5 Strategy Tester on historical data from the training period.

![](https://c.mql5.com/2/71/25370206423.png)

![](https://c.mql5.com/2/71/834335329349.png)

You can use any indicator parameters. However, make sure to use the same parameters when collecting a training dataset and testing the trained model. Also, save the parameters for the model operation. When preparing this article, I used the default settings for all indicators.

To regulate the number of collected passes, I use optimization for the _Agent_ parameter. This parameter was added to the EA only to regulate optimization passes and is not used in the EA code.

After collecting training data, we run the EA "...\\Experts\\FAQ\\Study.mq5" on the chart in real time. The EA trains models using the collected training dataset without performing trading operations. Therefore, the EA operation on a real chart will not affect your account balance.

![](https://c.mql5.com/2/71/3416845652314.png)

Typically, I use an iterative approach to train models. During this process, I alternate training models with collecting additional data into the training set. With this approach, the size of our training dataset is limited and is not able to cover the entire variety of Agent behaviors in the environment. During the next launches of the EA "...\\Experts\\FAQ\\Research.mq5", in the process of interaction with the environment, it is no longer guided by random policy. Our trained policy is used instead. Thus, we replenish the experience replay buffer with states and actions close to our policy. By doing so, we explore the environment around our policy, similar to the online learning process. This means that during subsequent training, we receive real rewards for actions instead of interpolated ones. This will help our Actor adjust the policy in the right direction.

At the same time, we periodically monitor training results on data not included in the training dataset.

![](https://c.mql5.com/2/71/911420337550.png)

During the training process, I managed to obtain a model capable of generating profit on the training and test datasets. While testing the trained model, during August 2023, the EA performed 87 trades, 45 of which were closed with a profit. This is equal to 51.72%. The profits of the highest and average profitable deal exceed the corresponding values of losing trades. During the testing period, the EA reached a profit factor of 1.61 and a recovery factor of 1.65.

![](https://c.mql5.com/2/71/5742889539377.png)

### Conclusion

In this article, we got acquainted with the Feature Aggregated Queries (FAQ) method for detecting objects in video. The authors of this method focused on initializing queries and aggregating them based on input data for detectors based on the Transformer architecture to balance the efficiency and performance of the model. They developed a query aggregation module that extends their representation to object detectors. This improves their performance on video tasks.

In addition, the authors of the FAQ method have extended the query aggregation module to a dynamic version, which can adaptively generate query initializations and adjust query aggregation weights according to the source data.

The proposed method is a plug-and-play module that can be integrated into most modern Transformer-based object detectors to solve problems in video and other time sequences.

In the practical part of this article, we implemented the proposed approaches using MQL5. We trained the model on real historical data and tested it on a time period outside the training set. Our test results confirm the effectiveness of the proposed approaches. However, the training and testing period is quite short to draw any specific conclusions. All the programs presented in this articles are intended only to demonstrate and test the proposed approaches.

### References

[FAQ: Feature Aggregated Queries for Transformer-based Video Object Detectors](https://www.mql5.com/go?link=https://arxiv.org/abs/2303.08319 "https://arxiv.org/abs/2205.10484")
[Other articles from this series](https://www.mql5.com/en/search#!keyword=Neural%20networks%20made%20easy&module=mql5_module_articles "https://www.mql5.com/en/search#!keyword=Neural%20networks%20made%20easy&module=mql5_module_articles")

### Programs used in the article

| # | Issued to | Type | Description |
| --- | --- | --- | --- |
| 1 | Research.mq5 | Expert Advisor | EA for collecting examples |
| 2 | ResearchRealORL.mq5 | Expert Advisor | EA for collecting examples using the Real-ORL method |
| 3 | Study.mq5 | Expert Advisor | Model training EA |
| 4 | Test.mq5 | Expert Advisor | Model testing EA |
| 5 | Trajectory.mqh | Class library | System state description structure |
| 6 | NeuroNet.mqh | Class library | A library of classes for creating a neural network |
| 7 | NeuroNet.cl | Code Base | OpenCL program code library |

Translated from Russian by MetaQuotes Ltd.

Original article: [https://www.mql5.com/ru/articles/14394](https://www.mql5.com/ru/articles/14394)

**Attached files** \|


[Download ZIP](https://www.mql5.com/en/articles/download/14394.zip "Download all attachments in the single ZIP archive")

[MQL5.zip](https://www.mql5.com/en/articles/download/14394/mql5.zip "Download MQL5.zip")(972.89 KB)

**Warning:** All rights to these materials are reserved by MetaQuotes Ltd. Copying or reprinting of these materials in whole or in part is prohibited.

This article was written by a user of the site and reflects their personal views. MetaQuotes Ltd is not responsible for the accuracy of the information presented, nor for any consequences resulting from the use of the solutions, strategies or recommendations described.

#### Other articles by this author

- [Neural Networks in Trading: Hybrid Graph Sequence Models (GSM++)](https://www.mql5.com/en/articles/17279)
- [Neural Networks in Trading: Two-Dimensional Connection Space Models (Final Part)](https://www.mql5.com/en/articles/17241)
- [Neural Networks in Trading: Two-Dimensional Connection Space Models (Chimera)](https://www.mql5.com/en/articles/17210)
- [Neural Networks in Trading: Multi-Task Learning Based on the ResNeXt Model (Final Part)](https://www.mql5.com/en/articles/17157)
- [Neural Networks in Trading: Multi-Task Learning Based on the ResNeXt Model](https://www.mql5.com/en/articles/17142)
- [Neural Networks in Trading: Hierarchical Dual-Tower Transformer (Final Part)](https://www.mql5.com/en/articles/17104)
- [Neural Networks in Trading: Hierarchical Dual-Tower Transformer (Hidformer)](https://www.mql5.com/en/articles/17069)

**[Go to discussion](https://www.mql5.com/en/forum/469753)**

![Creating a Daily Drawdown Limiter EA in MQL5](https://c.mql5.com/2/83/Creating_a_Daily_Drawdown_Limiter_EA_in_MQL5___LOGO.png)[Creating a Daily Drawdown Limiter EA in MQL5](https://www.mql5.com/en/articles/15199)

The article discusses, from a detailed perspective, how to implement the creation of an Expert Advisor (EA) based on the trading algorithm. This helps to automate the system in the MQL5 and take control of the Daily Drawdown.

![Neural networks made easy (Part 78): Decoder-free Object Detector with Transformer (DFFT)](https://c.mql5.com/2/70/Neural_networks_made_easy_Part_78____LOGO.png)[Neural networks made easy (Part 78): Decoder-free Object Detector with Transformer (DFFT)](https://www.mql5.com/en/articles/14338)

In this article, I propose to look at the issue of building a trading strategy from a different angle. We will not predict future price movements, but will try to build a trading system based on the analysis of historical data.

![How to Integrate Smart Money Concepts (BOS) Coupled with the RSI Indicator into an EA](https://c.mql5.com/2/83/Coupled_with_the_RSI_Indicator_into_an_EA____LOGO.png)[How to Integrate Smart Money Concepts (BOS) Coupled with the RSI Indicator into an EA](https://www.mql5.com/en/articles/15030)

Smart Money Concept (Break Of Structure) coupled with the RSI Indicator to make informed automated trading decisions based on the market structure.

![Creating an Interactive Graphical User Interface in MQL5 (Part 1): Making the Panel](https://c.mql5.com/2/83/Creation_of_an_Interactive_Graphical_User_Interface_in_MQL5.png)[Creating an Interactive Graphical User Interface in MQL5 (Part 1): Making the Panel](https://www.mql5.com/en/articles/15205)

This article explores the fundamental steps in crafting and implementing a Graphical User Interface (GUI) panel using MetaQuotes Language 5 (MQL5). Custom utility panels enhance user interaction in trading by simplifying common tasks and visualizing essential trading information. By creating custom panels, traders can streamline their workflow and save time during trading operations.

[![](https://www.mql5.com/ff/sh/zf7a2k61x98jzh89z2/01.png)Speed up your tradingUse our high-speed VPS for MetaTrader 4 and 5Learn more](https://www.mql5.com/ff/go?link=https://www.mql5.com/en/vps&a=qtrrsuiwuicrscmckjynyanztbditglq&s=c617dc80d90cfd3783ec1345eec2b419b281f10fec6eac77b3218984ac337259&uid=&ref=https://www.mql5.com/en/articles/14394&id=wdausxxqrpvhekbwjrjlhqjghyhesrqqau&fz_uniq=5070105307255869449)

This website uses cookies. Learn more about our [Cookies Policy](https://www.mql5.com/en/about/cookies).

![close](https://c.mql5.com/i/close.png)

![MQL5 - Language of trade strategies built-in the MetaTrader 5 client terminal](https://c.mql5.com/i/registerlandings/logo-2.png)

You are missing trading opportunities:

- Free trading apps
- Over 8,000 signals for copying
- Economic news for exploring financial markets

RegistrationLog in

latin characters without spaces

a password will be sent to this email

An error occurred


- [Log in With Google](https://www.mql5.com/en/auth_oauth2?provider=Google&amp;return=popup&amp;reg=1)

You agree to [website policy](https://www.mql5.com/en/about/privacy) and [terms of use](https://www.mql5.com/en/about/terms)

If you do not have an account, please [register](https://www.mql5.com/en/auth_register)

Allow the use of cookies to log in to the MQL5.com website.

Please enable the necessary setting in your browser, otherwise you will not be able to log in.

[Forgot your login/password?](https://www.mql5.com/en/auth_forgotten?return=popup)

- [Log in With Google](https://www.mql5.com/en/auth_oauth2?provider=Google&amp;return=popup)