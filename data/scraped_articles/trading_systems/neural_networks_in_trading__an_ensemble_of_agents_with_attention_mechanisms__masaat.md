---
title: Neural Networks in Trading: An Ensemble of Agents with Attention Mechanisms (MASAAT)
url: https://www.mql5.com/en/articles/16599
categories: Trading Systems, Expert Advisors, Machine Learning
relevance_score: 3
scraped_at: 2026-01-23T18:31:57.451823
---

[![](https://www.mql5.com/ff/si/h2ryn394uwcpxwmxc2.jpg)](https://www.mql5.com/ff/go?link=https%3A%2F%2Fwww.mql5.com%2Fen%2Feconomic-calendar%3Futm_source%3Dwww.mql5.com%26utm_medium%3Ddisplay.800.80%26utm_term%3Dopen.calendar%26utm_content%3Deconomic.calendar%26utm_campaign%3Den.0009.desktop.default&a=qdeulxgvibgwytgewnvfatbocjnnninc&s=5c0c60f00ff5f5bedb0fdf65d9d79eb820442eb43ffac2b85aa003224f9dba14&v=1&host=https%3A%2F%2Fwww.mql5.com%2Fff%2F&id=bfogggabsofabcpxuzmgaibarmaxasdrj&uid=utfxgpxuxumhyvqkfouodzlkfopctvcn&ssn=1769182315510773643&ssn_dr=0&ssn_sr=0&fv_date=1769182315&ref=https%3A%2F%2Fwww.mql5.com%2Fen%2Farticles%2F16599&back_ref=https%3A%2F%2Fwww.google.com%2F&title=Neural%20Networks%20in%20Trading%3A%20An%20Ensemble%20of%20Agents%20with%20Attention%20Mechanisms%20(MASAAT)%20-%20MQL5%20Articles&scr_res=1920x1080&ac=176918231594831256&fz_uniq=5069520886760932971&sv=2552)

MetaTrader 5 / Trading systems


### Introduction

Portfolio management of financial instruments is a key component of investment decision-making, aimed at increasing returns while minimizing risks through the dynamic allocation of capital across assets. The high volatility of financial markets, where asset prices depend on a multitude of factors, complicates the construction of an optimal portfolio that simultaneously addresses two conflicting objectives: maximizing profits and minimizing risks. Traditional financial models, built on various investment principles, often prove effective in a single market but may fail under the complex and dynamic conditions of modern markets.

In recent years, growing attention has been given to machine learning methods for analyzing non-stationary price series. Among these, deep learning and reinforcement learning strategies have demonstrated notable success in computational finance. However, price data in financial markets are typically noisy time series, where extracting signals indicative of future trends is challenging.

One promising approach is presented in the paper " [_Developing an attention-based ensemble learning framework for financial portfolio optimisation_](https://www.mql5.com/go?link=https://arxiv.org/abs/2404.08935 "https://arxiv.org/abs/2404.08935")". The authors introduce an innovative adaptive trading framework integrating attention mechanisms and time-series analysis ( _Multi-Agent and Self-Adaptive portfolio optimisation framework_ _integrated with Attention mechanisms and Time series_ _â€” MASAAT_). Within this framework, multiple agents are deployed to observe and analyze directional changes in asset prices at varying levels of granularity. The goal is to enable thorough portfolio rebalancing to balance returns and risks in highly volatile markets.

By applying directional movement filters with different thresholds to capture significant price changes, the agents first extract trend features from raw time series. This allows them to track market regime shifts from multiple perspectives. Such an approach introduces a novel way of generating tokens in sequences, enabling the Cross-Sectional Attention ( _CSA_) and Temporal Attention ( _TA_) modules within the agents to effectively capture both asset correlations and temporal dependencies. Specifically, when reconstructing feature maps, sequence tokens in the _CSA_ module are based on individual asset features, optimizing attention embeddings across assets, while tokens in the _TA_ module are based on individual time points, capturing relevance between current and past observations.

Furthermore, information on asset and temporal dependencies is integrated within a spatio-temporal attention block. With clearly defined roles for _CSA_ and _TA_, agents are equipped with richer insights into asset trends, allowing them to propose portfolios based on their unique perspectives. Ultimately, the portfolios generated by different agents are combined into a new ensemble portfolio that adapts dynamically to current market conditions. Even if a single agent misinterprets market trends and produces biased recommendations, the _MASAAT_ framework, through its multi-agent integration, can adaptively refine the final portfolio to mitigate negative outcomes.

### The MASAAT Algorithm

The _MASAAT_ framework applies multiple directional movement filters with varying thresholds to capture significant price fluctuations across multi-scale receptive fields, enabling analysis of potential influences on future price movements. These receptive fields represent different levels of asset price volatility, giving agents an intuitive perception of market dynamics. By reconstructing asset-oriented directional movement features in the _CSA_ module and time-point-oriented features in the _TA_ module into sequence tokens, the multi-agent _MASAAT_ framework simultaneously collects spatial and temporal information across different scales of price changes. This facilitates the identification of both the direction and magnitude of upcoming trends. Raw price series are directly transformed into asset- and time-oriented features, followed by cross-sectional and temporal analysis within the _CSA_ and _TA_ modules.

Notably, the _CSA_ and _TA_ modules are built on _Self-Attention_ encoders, where attention scores are calculated across the entire sequence of tokens. This allows for a fair estimation of similarity across all assets, unlike convolutional neural networks (CNNs), which are highly sensitive to local positional structures in feature maps and rely on kernel sizes. By usig attention scores that explicitly quantify token similarities, the trading signals generated by MASAAT are inherently more interpretable. Through spatio-temporal attention blocks, mappings are constructed between asset sequences and historical time-point sequences. This process generates embeddings that represent each asset's attention scores across all time points within the observation window. These embeddings are then used to propose portfolio allocations. A portfolio generator consolidates agent-level proposals into a revised ensemble portfolio, enabling adaptive responses to evolving market conditions.

Let _N_ be the number of assets, _M_ the number of observable market features, and _Ma_ the number of trading agents. For a given historical depth, each agent first observes price features ğ âˆˆ R_NÃ—MÃ—Tw_ over the observation window _Tw_. Then trend-based functions ğ_DC_={ğ_DC_,1, ğ_DC_,2,â€¦,ğ_DC,ğŒa_} âˆˆ R_M_ _a_, ğ _DC,i_ âˆˆ R_N_ _Ã—MÃ—Tw_ are extracted using directional movement filters. As mentioned above, the method ğ_DC,i_ are transformed into ğ _DC,i,CSA_ âˆˆ R_N_ _Ã—MT_ _w_ for the module _CSA_ and ğ_DC,i,TA_ âˆˆ R _TwÃ—NM_ for the module _Ğ¢Ğ_. The interdependences are then analyzed in the _Transformer_ encoder. Similarly, the raw price series ğ is transformed into ğ_CSA_ âˆˆ RNÃ—MTw and ğ_TA_ âˆˆ R_T_ _wÃ—NM_.

After analyzing token dependencies, _CSA_ and _TA_ modules output asset-oriented embeddings ğ_CSA_ âˆˆ R_N_ _Ã—D_ and time-oriented embeddings ğ_TA_ âˆˆ R_T_ _wÃ—_ _D_, where _D_ is the embedding vector dimension. These embeddings are merged to construct an updated portfolio, which is further integrated with outputs from other agents to obtain the final dependency vector _Wğ­_ and refine the portfolio.

After trading operations are executed, rewards _rt_ are collected and stored in the experience replay buffer _Ä_, along with _Wğ­_, ğ and ğ_DC_. Also, the Actor policy _Ï€_ is iteratively updated by sampling from _Ä_ using a policy gradient method.

Since higher returns typically come with higher risks, diversification is both crucial and challenging. Agents must assign appropriate weights to heterogeneous assets to achieve hedging effects. Thus, continuously learning asset correlations allows agents to manage risks more effectively in turbulent market conditions.

The trend features are transformed into sequence tokens before correlation analysis through _Self-Attention_ encoders. The optimized attention vector quantifies correlations between assets, where assets with similar attention vectors are inferred to share relevant characteristics.

Beyond asset correlation, _MASAAT_ also investigates temporal relevance across observation windows, aiming to predict price trends at multiple levels. In this case, each time point is treated as a sequence token, and correlations between time points are learned through _Transformer_ encoders. Two time points with similar attention vectors are considered to share comparable trend dynamics.

By aggregating information from _CSA_ and _TA_ modules, _MASAAT_ agents combine asset-level and time-level attention scores, estimating each assetâ€™s importance relative to each time point in the observation period. Each agent's proposed portfolio can be expressed as:

![](https://c.mql5.com/2/168/5611112883421__1.png)

where ğ•_i_ and _bi_ are learnable parameters of _MLP_.

The outputs of multiple agents, each observing price fluctuations at different granularities, are then integrated to form an ensemble portfolio responsive to the current financial environment. Compared to portfolios generated by individual agents, the multi-agent structure of _MASAAT_ provides multiple candidate portfolios derived from diverse perspectives. This significantly enhances the system adaptability, particularly in highly volatile markets.

The original visualization of the _MASAAT_ framework is provided below.

![](https://c.mql5.com/2/168/804172205040__1.png)![](https://c.mql5.com/2/168/6094389358264__1.png)

### Implementation in MQL5

After discussing the theoretical aspects of the _MASAAT_ framework, we now turn to the practical part of this article, where we present an implementation of our interpretation of the proposed approach using _MQL5_. As noted earlier, _MASAAT_ is a comprehensive framework. To maintain a clear separation of functionality across different blocks, we will design it as a modular structure composed of independent objects, each responsible for part of the _MASAAT_ functionality.

We begin with the trend detection mechanism. A [piecewise linear representation (PLR)](https://www.mql5.com/en/articles/15217) layer for time series is well-suited for identifying local trends. However, there is a limitation: the previously implemented object can only act as a single agent. Since _MASAAT_ requires flexible functionality for building models with multiple agents, we need a more scalable solution.

One option would be to use a dynamic array containing pointers to several PLR objects of the analyzed time series, each operating with different threshold values. However, this approach leads to sequential execution, which is not optimal. Instead, we will develop a new object that enables parallel operation of multiple trend-detection agents. To achieve this, we first need to extend the _OpenCL_ program with new kernels.

#### _OpenCL_ Program Extension

When attempting to adapt the existing PLR kernels, we faced the need to replace a single threshold parameter with a vector of threshold values, one for each agent. This change requires not only modifying the kernel algorithm but also restructuring the dependent objects. To simplify development, we created new forward and backward pass kernels, partially reusing the logic of the existing implementation.

For the feed-forward pass, we developed the _PLRMultiAgents_ kernel. It receives four data buffer pointers. Two buffers contain the raw time series and agent-specific threshold values. The other two buffers store the analysis results and trend-reversal flags.

```
__kernel void PLRMultiAgents(__global const float *inputs,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  __global float *outputs,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  __global int *isttp,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  const int transpose,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  __global const float *min_step
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â )
Â Â {
Â Â  const size_t i = get_global_id(0);
Â Â  const size_t lenth = get_global_size(0);
Â Â  const size_t v = get_global_id(1);
Â Â  const size_t variables = get_global_size(1);
Â Â  const size_t a = get_global_id(2);
Â Â  const size_t agents = get_global_size(2);
```

This kernel is executed in a 3D task space. The first dimension corresponds to the size of the analyzed sequence. The second dimension corresponds to the number of univariate series in a multimodal sequence. The third dimension corresponds to the number of agents. Within the kernel, each thread identifies its position across all task dimensions. After that we determine the offset in the data buffers.

```
//--- constants
Â Â  const int shift_in = ((bool)transpose ? (i * variables + v) : (v * lenth + i));
Â Â  const int step_in = ((bool)transpose ? variables : 1);
Â Â  const int shift_ag = a * lenth * variables;
```

It is important to note that all agents analyze the same multimodal sequence. Thus, the agent identifier affects only the buffer offset for results and threshold values.

After initialization, the kernel begins searching for trend reversal points (extrema). Each flow determines the presence of a trend reversal point at the position of the current element. The extreme points of the analyzed time series automatically receive the status of a trend reversal point, since they are a priori the extreme points of the segment.

```
//--- look for ttp
Â Â  float value = IsNaNOrInf(inputs[shift_in], 0);
Â Â  bool bttp = false;
Â Â  if(i == 0 || i == lenth - 1)
Â Â Â Â Â Â bttp = true;
```

For other points, the algorithm searches backward for the nearest element with a deviation exceeding the threshold. During this process, we record the minimum and maximum values in the checked interval.

```
Â Â  else
Â Â Â Â  {
Â Â Â Â Â Â float prev = value;
Â Â Â Â Â Â int prev_pos = i;
Â Â Â Â Â Â float max_v = value;
Â Â Â Â Â Â float max_pos = i;
Â Â Â Â Â Â float min_v = value;
Â Â Â Â Â Â float min_pos = i;
Â Â Â Â Â Â while(fmax(fabs(prev - max_v), fabs(prev - min_v)) < min_step[a] && prev_pos > 0)
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  prev_pos--;
Â Â Â Â Â Â Â Â  prev = IsNaNOrInf(inputs[shift_in - (i - prev_pos) * step_in], 0);
Â Â Â Â Â Â Â Â  if(prev >= max_v && (prev - min_v) < min_step[a])
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â max_v = prev;
Â Â Â Â Â Â Â Â Â Â Â Â max_pos = prev_pos;
Â Â Â Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â Â  if(prev <= min_v && (max_v - prev) < min_step[a])
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â min_v = prev;
Â Â Â Â Â Â Â Â Â Â Â Â min_pos = prev_pos;
Â Â Â Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â Â }
```

Search forward for the next element with the required deviation.

```
Â Â Â Â Â Â float next = value;
Â Â Â Â Â Â int next_pos = i;
Â Â Â Â Â Â while(fmax(fabs(next - max_v), fabs(next - min_v)) < min_step[a] && next_pos < (lenth - 1))
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  next_pos++;
Â Â Â Â Â Â Â Â  next = IsNaNOrInf(inputs[shift_in + (next_pos - i) * step_in], 0);
Â Â Â Â Â Â Â Â  if(next > max_v && (next - min_v) < min_step[a])
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â max_v = next;
Â Â Â Â Â Â Â Â Â Â Â Â max_pos = next_pos;
Â Â Â Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â Â  if(next < min_v && (max_v - next) < min_step[a])
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â min_v = next;
Â Â Â Â Â Â Â Â Â Â Â Â min_pos = next_pos;
Â Â Â Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â Â }
```

Determine whether the current element qualifies as an extremum.

```
Â Â Â Â Â Â if(
Â Â Â Â Â Â Â Â  (value >= prev && value > next) ||
Â Â Â Â Â Â Â Â  (value > prev && value == next) ||
Â Â Â Â Â Â Â Â  (value <= prev && value < next) ||
Â Â Â Â Â Â Â Â  (value < prev && value == next)
Â Â Â Â Â Â )
Â Â Â Â Â Â Â Â  if(max_pos == i || min_pos == i)
Â Â Â Â Â Â Â Â Â Â Â Â bttp = true;
Â Â Â Â  }
```

But here we should remember that when searching for elements with the minimum required deviation, we could collect a corridor of values from several elements of the sequence that form a certain extremum plateau. Therefore, an element receives a flag only if it is an extremum in such a corridor. If there are several elements with the same value, we assign the extremum flag to the first of them.

We save the obtained flag and clear the output buffer. At the same time, we synchronize the workgroup flows.

```
Â Â  isttp[shift_in + shift_ag] = (int)bttp;
Â Â  outputs[shift_in + shift_ag] = 0;
Â Â  barrier(CLK_LOCAL_MEM_FENCE);
```

Subsequent steps are performed only by threads associated with confirmed trend reversals. The rest do not meet the set conditions and practically complete the operations.

First we determine the position of the current extremum. For this we count all preceding extrema based on the saved flags up to the analyzed position and save the position of the previous extremum from the source data buffer in a local buffer.

```
//--- calc position
Â Â  int pos = -1;
Â Â  int prev_in = 0;
Â Â  int prev_ttp = 0;
Â Â  if(bttp)
Â Â Â Â  {
Â Â Â Â Â Â pos = 0;
Â Â Â Â Â Â for(int p = 0; p < i; p++)
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  int current_in = ((bool)transpose ? (p * variables + v) : (v * lenth + p));
Â Â Â Â Â Â Â Â  if((bool)isttp[current_in + shift_ag])
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â pos++;
Â Â Â Â Â Â Â Â Â Â Â Â prev_ttp = p;
Â Â Â Â Â Â Â Â Â Â Â Â prev_in = current_in;
Â Â Â Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â Â }
Â Â Â Â  }
```

Then we compute the parameters of the linear approximation for the segment.

```
//--- cacl tendency
Â Â  if(pos > 0 && pos < (lenth / 3))
Â Â Â Â  {
Â Â Â Â Â Â float sum_x = 0;
Â Â Â Â Â Â float sum_y = 0;
Â Â Â Â Â Â float sum_xy = 0;
Â Â Â Â Â Â float sum_xx = 0;
Â Â Â Â Â Â int dist = i - prev_ttp;
Â Â Â Â Â Â for(int p = 0; p < dist; p++)
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  float x = (float)(p);
Â Â Â Â Â Â Â Â  float y = IsNaNOrInf(inputs[prev_in + p * step_in], 0);
Â Â Â Â Â Â Â Â  sum_x += x;
Â Â Â Â Â Â Â Â  sum_y += y;
Â Â Â Â Â Â Â Â  sum_xy += x * y;
Â Â Â Â Â Â Â Â  sum_xx += x * x;
Â Â Â Â Â Â Â Â }
Â Â Â Â Â Â float slope = IsNaNOrInf((dist * sum_xy - sum_x * sum_y) / (dist > 1 ? (dist * sum_xx - sum_x * sum_x) : 1), 0);
Â Â Â Â Â Â float intercept = IsNaNOrInf((sum_y - slope * sum_x) / dist, 0);
```

After that, we save the obtained values in the results buffer.

```
Â Â Â Â Â Â int shift_out = ((bool)transpose ? ((pos - 1) * 3 * variables + v) : (v * lenth + (pos - 1) * 3)) + shift_ag;
Â Â Â Â Â Â outputs[shift_out] = slope;
Â Â Â Â Â Â outputs[shift_out + step_in] = intercept;
Â Â Â Â Â Â outputs[shift_out + 2 * step_in] = ((float)dist) / lenth;
Â Â Â Â  }
```

Each obtained segment is characterized by 3 parameters:

- _slope_ â€” the trend line angle,
- _intercept_ â€” the line offset in the data space,
- _dist_ â€” the normalized length of the segment.

Storing the sequence length as an integer value is not the best option in this case. Because for the efficient operation of the model, a normalized data presentation format is preferable. Therefore, we translate the integer segment size into a fraction of the length of the univariate sequence being analyzed. To do this, we divide the number of elements in the segment by the number of elements in the entire sequence of the univariate time series. In order not to fall into the "trap" of integer operations, we will first convert the number of elements in the segment from _int_ to the _float_ type.

Additionally, we will create a separate branch of operations for the last segment. At this stage, we do not know the number of segments that will be formed at any given point in time. Hypothetically, in extreme scenarios (e.g., small thresholds and high volatility), reversals may occur at nearly every element. Although unlikely, this case would significantly increase data volume. At the same time, we do not want to lose data.

Therefore, we proceed from a priori knowledge of the representation of time series in _MQL5_ and understanding the structure of the analyzed data: the latest data in time is at the beginning of our time series. Let's dwell on them in more detail. Data at the end of the analyzed sequence happened earlier in history and thus has less influence on subsequent events. Although we will not exclude such dependencies.

Therefore, to write the results, we use a data buffer size similar to the size of the input time series tensor. This allows us to write segments 3 times smaller than the sequence length (3 elements to write 1 segment). We expect that this volume is more than sufficient. However, if there are more segments, we merge the data of the last segments into 1 to avoid data loss.

```
Â Â  else
Â Â Â Â  {
Â Â Â Â Â Â if(pos == (lenth / 3))
Â Â Â Â Â Â Â Â {
Â Â Â Â Â Â Â Â  float sum_x = 0;
Â Â Â Â Â Â Â Â  float sum_y = 0;
Â Â Â Â Â Â Â Â  float sum_xy = 0;
Â Â Â Â Â Â Â Â  float sum_xx = 0;
Â Â Â Â Â Â Â Â  int dist = lenth - prev_ttp;
Â Â Â Â Â Â Â Â  for(int p = 0; p < dist; p++)
Â Â Â Â Â Â Â Â Â Â  {
Â Â Â Â Â Â Â Â Â Â Â Â float x = (float)(p);
Â Â Â Â Â Â Â Â Â Â Â Â float y = IsNaNOrInf(inputs[prev_in + p * step_in], 0);
Â Â Â Â Â Â Â Â Â Â Â Â sum_x += x;
Â Â Â Â Â Â Â Â Â Â Â Â sum_y += y;
Â Â Â Â Â Â Â Â Â Â Â Â sum_xy += x * y;
Â Â Â Â Â Â Â Â Â Â Â Â sum_xx += x * x;
Â Â Â Â Â Â Â Â Â Â  }
Â Â Â Â Â Â Â Â  float slope = IsNaNOrInf((dist * sum_xy - sum_x * sum_y) / (dist > 1 ? (dist * sum_xx - sum_x * sum_x) : 1),0);
Â Â Â Â Â Â Â Â  float intercept = IsNaNOrInf((sum_y - slope * sum_x) / dist, 0);
Â Â Â Â Â Â Â Â  int shift_out = ((bool)transpose ? ((pos - 1) * 3 * variables + v) : (v * lenth + (pos - 1) * 3)) + shift_ag;
Â Â Â Â Â Â Â Â  outputs[shift_out] = slope;
Â Â Â Â Â Â Â Â  outputs[shift_out + step_in] = intercept;
Â Â Â Â Â Â Â Â  outputs[shift_out + 2 * step_in] = IsNaNOrInf((float)dist / lenth, 0);
Â Â Â Â Â Â Â Â }
Â Â Â Â  }
Â Â }
```

In most cases, we expect to have fewer segments, and then the last elements of our result buffer will be filled with zero values.

As you can see, we do not use trainable parameters in the feed-forward pass algorithm. So, the backpropagation pass is reduced to error gradient distribution. This functionality is implemented in the _PLRMultiAgentsGradient_ kernel.

All agents analyze the same time series. Therefore, gradients from all agents must be aggregated at the raw data level. Given the expected modest number of agents, we chose not to overcomplicate the kernel. Instead, we reuse the single-agent gradient distribution algorithm. However, we also add a loop to collect gradients from all agents and a parameter specifying their number. I encourage you to explore their implementations independently. The complete _OpenCL_ program, including these kernels, is provided in the attachment.

#### Trend Detection Mechanism Object

Having completed the _OpenCL_-side implementation, we now move to our main library and implement the multi-agent trend detection algorithm within the object _CNeuronPLRMultiAgentsOCL_. As you may notice, this object essentially extends the previously developed piecewise linear representation (PLR) of a time series. This is why we selected it as the parent class. The structure of the new object is presented below.

```
class CNeuronPLRMultiAgentsOCLÂ Â :Â Â public CNeuronPLROCL
Â Â {
protected:
Â Â  intÂ Â Â Â Â Â Â Â Â Â Â Â Â Â  iAgents;
Â Â  CBufferFloatÂ Â Â Â Â Â cMinDistance;
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â feedForward(CNeuronBaseOCL *NeuronOCL);
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â calcInputGradients(CNeuronBaseOCL *prevLayer);

public:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  CNeuronPLRMultiAgentsOCL(void)Â Â : iAgents(1) {};
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ~CNeuronPLRMultiAgentsOCL(void) {};
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint window_in, uint units_count, bool transpose,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â vector<float> &min_distance,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ENUM_OPTIMIZATION optimization_type, uint batch);
Â Â  //---
Â Â  virtual intÂ Â Â Â Â Â  Type(void)Â Â  constÂ Â  {Â Â return defNeuronPLRMultiAgentsOCL;Â Â  }
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â Save(int const file_handle);
Â Â  virtual boolÂ Â Â Â Â Â Load(int const file_handle);
Â Â  virtual voidÂ Â Â Â Â Â SetOpenCL(COpenCLMy *obj);
Â Â };
```

In this new class, we declare a constant defining the number of active agents ( _iAgents_) and a buffer for storing the threshold values of feature changes in the analyzed time series ( _cMinDistance_).

Since all internal objects are declared statically, we can keep the constructor and destructor empty. The initialization of these declared and inherited objects is performed in the _Init_ method.

```
bool CNeuronPLRMultiAgentsOCL::Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint window_in, uint units_count, bool transpose,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â vector<float> &min_distance,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ENUM_OPTIMIZATION optimization_type, uint batch)
Â Â {
Â Â  iAgents = (int)min_distance.Size();
Â Â  if(iAgents <= 0)
Â Â Â Â Â Â return false;
```

Note that the method takes only a vector of threshold values as input. We do not explicitly pass the number of agents. The number is derived from the size of the threshold vector itself. This reduces the number of external parameters and guarantees consistency between the threshold parameter and the buffer length.

Within the method, after saving the agent count in an internal variable and validating it (at least one agent is required for proper operation), we call the initialization method of the base object, which sets up the core interfaces.

```
Â Â  if(!CNeuronBaseOCL::Init(numOutputs, myIndex, open_cl, window_in * units_count * iAgents, optimization_type, batch))
Â Â Â Â Â Â return false;
```

Importantly, we call the base object's Init method, not the direct parent's one. This is because the size of the results buffer is scaled proportionally to the number of agents. However, this requires a deeper reinitialization of inherited components.

First, we save the values of the received parameters in inherited variables.

```
Â Â  iVariables = (int)window_in;
Â Â  iCount = (int)units_count;
Â Â  bTranspose = transpose;
```

And then we initialize the buffer of extremum flags.

```
Â Â  icIsTTP = OpenCL.AddBuffer(sizeof(int) * Neurons(), CL_MEM_READ_WRITE);
Â Â  if(icIsTTP < 0)
Â Â Â Â Â Â return false;
```

Note that these flags are recalculated after every feed-forward pass. Their size matches that of the results buffer. Obviously, there is no need to store their values permanently. Thus, the buffer is created only in the _OpenCL_ context memory. The object retains only a pointer to it.

Next we initialize the threshold buffer.

```
Â Â  if(!cMinDistance.AssignArray(min_distance) ||
Â Â Â Â Â Â !cMinDistance.BufferCreate(OpenCL))
Â Â Â Â Â Â return false;
//---
Â Â  return true;
Â Â }
```

After that, we complete the method by returning the logical result of the initialization process to the calling program.

The feed-forward and backpropagation methods are also overridden. However, their sole function is to invoke the OpenCL kernels described earlier. Since their logic is straightforward, we leave them for independent study.

This concludes the implementation of the multi-agent trend detection object _CNeuronPLRMultiAgentsOCL_. The full source code of its methods is provided in the attachment.

#### Cross-Sectional Attention Module ( _CSA_)

Once we obtain the multi-scale piecewise linear representations of the analyzed time series, each agent processes its assigned scale for in-depth analysis. Within the _MASAAT_ framework, time series are analyzed in two projections: across assets and across time points.

Time series analysis within the _MASAAT_ framework is performed by the module of cross-asset attention, which we implement as a _CNeuronCrossSectionalAnalysis_ object. But before we get down to implementation, let's talk about the _CSA_ module construction algorithm.

As explained in the theoretical section of _MASAAT_ description, the _CSA_ module uses a _Self-Attention_ encoder to capture asset dependencies. Our library already contains several encoder implementations. However, there is a nuance: in MASAAT, multiple agents work in parallel, with each analyzing dependencies only within its assigned subset of the data. After review, we can identify a suitable solution.

Fore example, the _[CNeuronMVMHAttentionMLKV](https://www.mql5.com/en/articles/15498#para31)_ block for independent channel analysis, originally developed for the _InjectTST_ framework. Not a bad solution. While this block is designed to analyze dependencies across multiple scales of a single asset, our task is to find dependencies between different assets within one scale. To adapt it, we first transpose the three-dimensional input tensor along its first two axes. We already have such a transposition layer in our library: _CNeuronTransposeRCDOCL_.

We've decided on the encoder. But before feeding data into the encoder, we also need to generate asset trajectory embeddings. The MASAAT authors suggest using an _MLP_ with shared parameters across assets. Following our convention, we replace the MLP with a convolutional layer. Specifically, we add a single convolutional layer with _GELU_ activation. The second _MLP_ role (generating _Query_, _Key_, _Value_ entities) is handled internally by the encoder itself.

This will be the structure of our _CSA_ module. In it, we will successively use a data transposition layer, a convolutional embedding layer, and an independent channel analysis block (Self-Attention encoder). For efficiency, we place the convolutional layer before transposition. The result of the operations will not change. However, this positively affects the effectiveness of the solution.

We feed some representation of the time series with the price movements of the analyzed assets to the _CSA_ module. Consequently, as the depth of the analyzed history increases, the volume of source data also increases. Since the PLR often contains many zero-filled elements, smaller embeddings can be used. This reduces the size of the tensor that needs to be transposed after the convolutional embedding layer operations, decreasing computational overhead and improving performance.

After identifying the key aspects of implementation, we can move on to constructing our new object _CNeuronCrossSectionalAnalysis_. Its structure is presented below.

```
class CNeuronCrossSectionalAnalysis :Â Â public CNeuronMVMHAttentionMLKV
Â Â {
protected:
Â Â  CNeuronConvOCLÂ Â Â Â Â Â Â Â Â Â cEmbeding;
Â Â  CNeuronTransposeRCDOCLÂ Â cTransposeRCD;
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â feedForward(CNeuronBaseOCL *NeuronOCL) override;
Â Â  virtual boolÂ Â Â Â Â Â calcInputGradients(CNeuronBaseOCL *prevLayer) override;
Â Â  virtual boolÂ Â Â Â Â Â updateInputWeights(CNeuronBaseOCL *NeuronOCL) override;

public:
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  CNeuronCrossSectionalAnalysis(void) {};
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â ~CNeuronCrossSectionalAnalysis(void) {};
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint window, uint window_key, uint heads, uint heads_kv,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint units_count, uint layers, uint layers_to_one_kv,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â uint variables, ENUM_OPTIMIZATION optimization_type, uint batch) override;
Â Â  //---
Â Â  virtual intÂ Â Â Â Â Â  Type(void)Â Â  const overrideÂ Â  {Â Â return defNeuronCrossSectionalAnalysis;Â Â  }
Â Â  //---
Â Â  virtual boolÂ Â Â Â Â Â Save(int const file_handle) override;
Â Â  virtual boolÂ Â Â Â Â Â Load(int const file_handle) override;
Â Â  virtual boolÂ Â Â Â Â Â WeightsUpdate(CNeuronBaseOCL *source, float tau) override;
Â Â  virtual voidÂ Â Â Â Â Â SetOpenCL(COpenCLMy *obj) override;
Â Â };
```

Note that we use the Independent Channel Analysis block as the parent class. This solution allows us to reuse its methods directly rather than embedding it as an internal component. We declare other objects as static and thus we can leave the class constructor and destructor empty. Initialization is performed in the _Init_ method, whose parameters mirror those of the parent class.

```
bool CNeuronCrossSectionalAnalysis::Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
Â Â Â Â Â Â                                    uint window, uint window_key, uint heads, uint heads_kv,
Â Â Â Â Â Â                                    uint units_count, uint layers, uint layers_to_one_kv, uint variables,
Â Â Â Â Â Â                                    ENUM_OPTIMIZATION optimization_type, uint batch)
Â Â {
Â Â  if(!CNeuronMVMHAttentionMLKV::Init(numOutputs, myIndex, open_cl, window_key, window_key, heads, heads_kv,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â variables, layers, layers_to_one_kv, units_count, optimization_type, batch))
Â Â Â Â Â Â return false;
```

In the method body, as usual, we first call the relevant method of the parent class. There is one caveat. While implementing the _CSA_ module functionality, we plan to make full use of all inherited methods. Within the feed-forward pass, the input of the parent class method will be fed with transposed embeddings of the raw data. Therefore, when calling the initialization method of the parent class, we resize the source data window to match the embedding dimension and swap the parameters of the analyzed sequence length with the number of independent variables.

After the initialization operations of the parent class objects have been successfully completed, we sequentially initialize the convolutional embedding and data transposition layer.

```
Â Â  if(!cEmbeding.Init(0, 0, OpenCL, window, window, window_key, units_count, variables, optimization, iBatch))
Â Â Â Â Â Â return false;
Â Â  cEmbeding.SetActivationFunction(GELU);
Â Â  if(!cTransposeRCD.Init(0,1,OpenCL,variables,units_count,window_key,optimization,iBatch))
Â Â Â Â Â Â return false;
```

After that, we forcibly disable the activation function and terminate the method, having previously returned the logical result of the operations to the calling program.

```
Â Â  SetActivationFunction(None);
//---
Â Â  return true;
Â Â }
```

Next, we build the feed-forward pass algorithm of our CSA module in the _feedForward_ method. Everything is quite straightforward here. In the method parameters, we receive a pointer to the input data object, which we immediately pass to the identically named method of the convolutional layer.

```
bool CNeuronCrossSectionalAnalysis::feedForward(CNeuronBaseOCL *NeuronOCL)
Â Â {
Â Â  if(!cEmbeding.FeedForward(NeuronOCL))
Â Â Â Â Â Â return false;
Â Â  if(!cTransposeRCD.FeedForward(cEmbeding.AsObject()))
Â Â Â Â  return false;
//---
Â Â  return CNeuronMVMHAttentionMLKV::feedForward(cTransposeRCD.AsObject());
Â Â }
```

We transpose the outputs of the convolutional layer and pass them to the identically named method of the parent class. The method concludes by returning the logical result of the operation to the calling program.

The backpropagation algorithm is also simple. Therefore, I suggest you explore it independently. We complete our work on the _CNeuronCrossSectionalAnalysis_ object. You can find the full code of all these methods in the attachment.

Our working day is now over. However, the work is not finished yet. Let's take a short break, and in the next article, we will bring the project to its logical conclusion.

### Conclusion

In this article, we explored the Multi-Agent Self-Adaptive Attention-based Time Series framework ( _MASAAT_) for portfolio optimization, which employs an ensemble of trading agents to analyze price data from multiple perspectives. This reduces the bias of generated trading actions. Each agent performs cross-sectional and temporal analyses using attention mechanisms to capture correlations between assets and time points, followed by a spatio-temporal fusion module to integrate the extracted information.

In the practical part, we began implementing our own interpretation of MASAAT in _MQL5_, including the multi-agent trend detection mechanism and the cross-sectional attention module. In the next article, we will continue this work and evaluate the performance of the implemented solution on real historical data.

#### References

- [Developing An Attention-Based Ensemble Learning Framework for Financial Portfolio Optimisation](https://www.mql5.com/go?link=https://arxiv.org/abs/2404.08935 "Developing An Attention-Based Ensemble Learning Framework for Financial Portfolio Optimisation")
- [Other articles from this series](https://www.mql5.com/en/search#!keyword=Neural%20networks%20made%20easy&module=mql5_module_articles "https://www.mql5.com/en/search#!keyword=Neural%20networks%20made%20easy&module=mql5_module_articles")

#### Programs used in the article

| # | Name | Type | Description |
| --- | --- | --- | --- |
| 1 | Research.mq5 | Expert Advisor | Expert Advisor for collecting samples |
| 2 | ResearchRealORL.mq5 | Expert Advisor | Expert Advisor for collecting samples using the Real-ORL method |
| 3 | Study.mq5 | Expert Advisor | Model training Expert Advisor |
| 4 | Test.mq5 | Expert Advisor | Model testing Expert Advisor |
| 5 | Trajectory.mqh | Class library | System state description structure |
| 6 | NeuroNet.mqh | Class library | A library of classes for creating a neural network |
| 7 | NeuroNet.cl | Code Base | OpenCL program code library |

Translated from Russian by MetaQuotes Ltd.

Original article: [https://www.mql5.com/ru/articles/16599](https://www.mql5.com/ru/articles/16599)

**Attached files** \|


[Download ZIP](https://www.mql5.com/en/articles/download/16599.zip "Download all attachments in the single ZIP archive")

[MQL5.zip](https://www.mql5.com/en/articles/download/16599/mql5.zip "Download MQL5.zip")(2222.61 KB)

**Warning:** All rights to these materials are reserved by MetaQuotes Ltd. Copying or reprinting of these materials in whole or in part is prohibited.

This article was written by a user of the site and reflects their personal views. MetaQuotes Ltd is not responsible for the accuracy of the information presented, nor for any consequences resulting from the use of the solutions, strategies or recommendations described.

#### Other articles by this author

- [Neural Networks in Trading: Hybrid Graph Sequence Models (GSM++)](https://www.mql5.com/en/articles/17279)
- [Neural Networks in Trading: Two-Dimensional Connection Space Models (Final Part)](https://www.mql5.com/en/articles/17241)
- [Neural Networks in Trading: Two-Dimensional Connection Space Models (Chimera)](https://www.mql5.com/en/articles/17210)
- [Neural Networks in Trading: Multi-Task Learning Based on the ResNeXt Model (Final Part)](https://www.mql5.com/en/articles/17157)
- [Neural Networks in Trading: Multi-Task Learning Based on the ResNeXt Model](https://www.mql5.com/en/articles/17142)
- [Neural Networks in Trading: Hierarchical Dual-Tower Transformer (Final Part)](https://www.mql5.com/en/articles/17104)
- [Neural Networks in Trading: Hierarchical Dual-Tower Transformer (Hidformer)](https://www.mql5.com/en/articles/17069)

**[Go to discussion](https://www.mql5.com/en/forum/494979)**

![Big Bang - Big Crunch (BBBC) algorithm](https://c.mql5.com/2/108/16701-logo.png)[Big Bang - Big Crunch (BBBC) algorithm](https://www.mql5.com/en/articles/16701)

The article presents the Big Bang - Big Crunch method, which has two key phases: cyclic generation of random points and their compression to the optimal solution. This approach combines exploration and refinement, allowing us to gradually find better solutions and open up new optimization opportunities.

![Overcoming The Limitation of Machine Learning (Part 3): A Fresh Perspective on Irreducible Error](https://c.mql5.com/2/167/19371-overcoming-the-limitation-of-logo.png)[Overcoming The Limitation of Machine Learning (Part 3): A Fresh Perspective on Irreducible Error](https://www.mql5.com/en/articles/19371)

This article takes a fresh perspective on a hidden, geometric source of error that quietly shapes every prediction your models make. By rethinking how we measure and apply machine learning forecasts in trading, we reveal how this overlooked perspective can unlock sharper decisions, stronger returns, and a more intelligent way to work with models we thought we already understood.

![Market Simulation (Part 01): Cross Orders (I)](https://c.mql5.com/2/107/Simulat6o_de_mercado_Parte_01_Cross_Order_I_LOGO.png)[Market Simulation (Part 01): Cross Orders (I)](https://www.mql5.com/en/articles/12536)

Today we will begin the second stage, where we will look at the market replay/simulation system. First, we will show a possible solution for cross orders. I will show you the solution, but it is not final yet. It will be a possible solution to a problem that we will need to solve in the near future.

![Building a Professional Trading System with Heikin Ashi (Part 1): Developing a custom indicator](https://c.mql5.com/2/165/19260-building-a-professional-trading-logo.png)[Building a Professional Trading System with Heikin Ashi (Part 1): Developing a custom indicator](https://www.mql5.com/en/articles/19260)

This article is the first installment in a two-part series designed to impart practical skills and best practices for writing custom indicators in MQL5. Using Heikin Ashi as a working example, the article explores the theory behind Heikin Ashi charts, explains how Heikin Ashi candlesticks are calculated, and demonstrates their application in technical analysis. The centerpiece is a step-by-step guide to developing a fully functional Heikin Ashi indicator from scratch, with clear explanations to help readers understand what to code and why. This foundational knowledge sets the stage for Part Two, where we will build an expert advisor that trades based on Heikin Ashi logic.

[![](https://www.mql5.com/ff/sh/qv94j0cd8n2n55z9z2/01.png)![](https://www.mql5.com/ff/sh/qv94j0cd8n2n55z9z2/02.png)Boost your trading experienceRead our book "MQL5 Programming for Traders"Begin](https://www.mql5.com/ff/go?link=https://www.mql5.com/en/book%3Futm_source=www.mql5.com%26utm_medium=display%26utm_term=read.algobook%26utm_content=visit.page%26utm_campaign=algobook.promo.04.2024&a=heclgjpfbvfghpmyaciuaesdtswflupo&s=4255fbe1b8cbc4d1b40afbaebf4235e5ace8b5103cba60d996897a03d588556f&uid=&ref=https://www.mql5.com/en/articles/16599&id=wdausxxqrpvhekbwjrjlhqjghyhesrqqau&fz_uniq=5069520886760932971)

This website uses cookies. Learn more about our [Cookies Policy](https://www.mql5.com/en/about/cookies).

![close](https://c.mql5.com/i/close.png)

![MQL5 - Language of trade strategies built-in the MetaTrader 5 client terminal](https://c.mql5.com/i/registerlandings/logo-2.png)

You are missing trading opportunities:

- Free trading apps
- Over 8,000 signals for copying
- Economic news for exploring financial markets

RegistrationLog in

latin characters without spaces

a password will be sent to this email

An error occurred


- [Log in With Google](https://www.mql5.com/en/auth_oauth2?provider=Google&amp;return=popup&amp;reg=1)

You agree to [website policy](https://www.mql5.com/en/about/privacy) and [terms of use](https://www.mql5.com/en/about/terms)

If you do not have an account, please [register](https://www.mql5.com/en/auth_register)

Allow the use of cookies to log in to the MQL5.com website.

Please enable the necessary setting in your browser, otherwise you will not be able to log in.

[Forgot your login/password?](https://www.mql5.com/en/auth_forgotten?return=popup)

- [Log in With Google](https://www.mql5.com/en/auth_oauth2?provider=Google&amp;return=popup)