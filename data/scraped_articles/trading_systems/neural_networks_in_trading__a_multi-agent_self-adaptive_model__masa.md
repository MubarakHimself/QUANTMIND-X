---
title: Neural Networks in Trading: A Multi-Agent Self-Adaptive Model (MASA)
url: https://www.mql5.com/en/articles/16537
categories: Trading Systems, Expert Advisors, Machine Learning
relevance_score: 3
scraped_at: 2026-01-23T18:32:48.530935
---

[![](https://www.mql5.com/ff/si/6pp0j40fqxpxwmxc2.gif)](https://www.mql5.com/ff/go?link=https%3A%2F%2Ftrade.metatrader5.com%2Fterminal%3Futm_source%3Dwww.mql5.com%26utm_medium%3Ddisplay.800.80%26utm_term%3Dtrade.in.browser%26utm_content%3Dmt5.web.platform%26utm_campaign%3Den.0009.desktop.default&a=luckhiizjxvmvgigcufevttapwwrwbld&s=08cd1d929f27358481aded3c1c5f4e75a9bd5f52c477127afef2a5c532aec5c5&v=1&host=https%3A%2F%2Fwww.mql5.com%2Fff%2F&id=bfogggabsofabcpxuzmgaibarmaxasdrj&uid=aqttnmdcylssujlsyzuxvzjqcdzfrrvd&ssn=1769182367095614051&ssn_dr=0&ssn_sr=0&fv_date=1769182367&ref=https%3A%2F%2Fwww.mql5.com%2Fen%2Farticles%2F16537&back_ref=https%3A%2F%2Fwww.google.com%2F&title=Neural%20Networks%20in%20Trading%3A%20A%20Multi-Agent%20Self-Adaptive%20Model%20(MASA)%20-%20MQL5%20Articles&scr_res=1920x1080&ac=176918236713546394&fz_uniq=5069534153914910366&sv=2552)

MetaTrader 5 / Trading systems


### Introduction

Computer technologies are becoming an integral part of financial analytics, offering innovative approaches to solving complex problems. In recent years, reinforcement learning (RL) has proven its effectiveness in dynamic portfolio management under the conditions of turbulent financial markets. However, existing methods often concentrate on maximizing returns while paying insufficient attention to risk management—particularly under uncertainty caused by pandemics, natural disasters, and regional conflicts.

To address this limitation, the study " [_Developing A Multi-Agent and Self-Adaptive Framework with Deep Reinforcement Learning for Dynamic Portfolio Risk Management_](https://www.mql5.com/go?link=https://arxiv.org/abs/2402.00515 "https://arxiv.org/abs/2402.00515")" introduces _MASA_ ( _**M** ulti- **A** gent and **S** elf- **A** daptive_). MASA integrates two interacting agents: the first optimizes returns using the _[TD3](https://www.mql5.com/en/articles/12892)_ algorithm, while the second minimizes risks through evolutionary algorithms or other optimization methods. In addition, _MASA_ incorporates a market observer that leverages deep neural networks to analyze market trends and provide feedback.

The authors tested _MASA_ on data from the _CSI 300_, _Dow Jones Industrial Average_ ( _DJIA_), and _S&P 500_ indices over the past 10 years. Their results demonstrate that _MASA_ outperforms traditional _RL_-based approaches in portfolio management.

### 1\. The MASA Algorithm

To overcome the limitations of conventional _RL_ approaches, which tend to focus excessively on return optimization, the authors propose a multi-agent self-adaptive architecture ( _MASA_). This structure employs two interactive and reactive agents (one based on _RL_, the other on an alternative optimization algorithm) to establish a fundamentally new multi-agent _RL_ scheme. The objective is to dynamically balance the trade-off between portfolio returns and potential risks, particularly under volatile market conditions.

Within this architecture, the RL _agent_, built on the _TD3_ algorithm, optimizes overall portfolio returns. Simultaneously, the alternative optimization agent adapts the portfolio generated by the _RL_ agent, minimizing risks after incorporating market trend assessments provided by the market observer.

This clear functional separation allows the model to continuously learn and adapt to the underlying dynamics of financial markets. As a result, _MASA_ produces more balanced portfolios, both in terms of profitability and risk, compared to approaches based solely on _RL_.

Importantly, the _MASA_ framework employs a loosely coupled, pipeline-like computational model across its three intelligent interacting agents. Thus, the general approach based on multi-agent _RL_ ensures resilience and robustness: the system continues operating effectively even if one of the agents fails.

Before the iterative training process begins, all relevant information is initialized, including the _RL_ policy and the market state data maintained by the _Market Observer_ agent.

During training, information about the current market state _O_ _t_ (e.g., the most recent upward or downward trends in the underlying market over the past few trading days) is collected for analysis by the Market Observer. In parallel, the reward from the previously executed action _At−1,Final_ is used as feedback for the _RL_ algorithm to refine the _RL agent_ behavior policy.

The Market Observer is then activated to compute the proposed risk boundary _σs,t_ and the market vector _Vm,_ _t_, which serve as additional features for updating both the _RL agent_ and the _Controller_ in response to current market conditions.

To ensure flexibility and adaptability, the _MASA_ framework can incorporate a variety of approaches, including algorithmic models or deep neural networks. More importantly, both _RL_-based and alternative optimization-based agents are inherently safeguarded by continuous access to current market information, which provides the most valuable feedback from the trading environment. The insights generated by the Market Observer are used exclusively as auxiliary information, enabling faster adaptation and improved performance of both the _RL agent_ and the Controller, particularly in highly volatile markets.

In worst-case scenarios, when the Market Observer generates misleading signals due to "noise", potentially affecting the other agents' decision-making, the adaptive nature of _RL_ reward mechanism allows the system to re-align with the underlying trading environment during subsequent training iterations. Furthermore, the Market Observer's self-correcting capability over time helps mitigate the effects of misleading signals, ensuring stability across longer trading horizons.

Experimental results show that both RL-based agents and alternative optimizers demonstrate substantial performance improvements - even when the Market Observer is implemented with relatively simple algorithmic methods. This outcome highlights _MASA_'s robustness when tested on complex datasets such as _CSI 300_, _DJIA_, and _S&P 500_ over a 10-year period.

Nevertheless, to fully understand the long-term impact of the Market Observer's input on the other two agents to which the proposed _MASA_ framework should be applied, further analysis is required across more complex datasets and different application domains.

After the Market Observer is activated, the _RL agent_ generates the current action _At,RL_ in the form of portfolio weights. These weights may then be revised by the _Controller_, which applies an alternative optimization algorithm after considering its own risk management strategy as well as the market conditions identified by the Observer. Thanks to this loosely coupled, pipeline-based model, _MASA_ functions as a robust Multi-Agent Aystem ( _MAS_), maintaining operational integrity even if one agent fails.

Guided by its reward-based mechanism, _MASA_ adapts seamlessly to continuously evolving environments. The decision-making agents iteratively enhance portfolio performance with respect to both return and risk objectives, informed by valuable feedback from the Market Observer. Simultaneously, its reward mechanism incorporates an entropy-based divergence measure to encourage diversity in the set of generated actions as an intelligent and adaptive strategy essential for coping with the volatility of different financial markets.

The original visualization of the MASA framework is provided below.

![](https://c.mql5.com/2/164/1835293561756.png)

### 2\. Implementation in MQL5

After reviewing the theoretical aspects of the _MASA_ method, we now move on to the practical part of the article, where we implement our interpretation of the proposed approaches using _MQL5_.

As mentioned earlier, the _MASA_ framework consists of three agents. For better readability and clarity of code, we will create a separate object for each agent and later combine them into a unified structure.

#### 2.1 Market Observer Agent

We begin by developing the Market Observer agent. The authors of _MASA_ emphasize that a variety of algorithms can be applied for market analysis - ranging from simple analytical methods to advanced deep learning models. The primary task of the Market Observer is to identify key trends in order to forecast the most probable upcoming movements.

In our implementation, we use a hybrid approach. First, we apply a [piecewise-linear representation algorithm](https://www.mql5.com/en/articles/15217) to capture current market tendencies. Next, we analyze dependencies among the identified trends of individual univariate sequences using an [attention module with relative positional encoding](https://www.mql5.com/en/articles/16097). Finally, at the output stage, we attempt to forecast the most probable market behavior over a defined planning horizon using an _MLP_.

This composite algorithm for the Market Observer is encapsulated in a new object _CNeuronMarketObserver_. Its structure is presented below.

```
class CNeuronMarketObserver   :  public CNeuronRMAT
  {
public:
                     CNeuronMarketObserver(void)   {};
                    ~CNeuronMarketObserver(void)   {};
   virtual bool      Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
                          uint window, uint window_key, uint units_count,
                          uint heads, uint layers, uint forecast,
                          ENUM_OPTIMIZATION optimization_type, uint batch);
   //---
   virtual int       Type(void) override   const   {  return defNeuronMarketObserver; }
  };
```

The algorithm follows a linear structure. For such a structure, the _CNeuronRMAT_ class designed to support small-scale linear models is a suitable parent class for our new object. This allows us to define the Market Observer's structure primarily within the _Init_ initialization method. The main functionality is already handled by the parent class.

The parameters of the _Init_ method specify the constants that define the architecture of the Market Observer agent. These include:

- window — the size of the vector describing a single sequence element (number of univariate time series);
- window\_key — the dimensionality of internal attention components ( _Query, Key, Value_);
- units\_count — the historical depth of data used for analysis;
- heads — the number of attention heads;
- layers — the number of attention layers;
- forecast — the forecasting horizon for the upcoming movement.

```
bool CNeuronMarketObserver::Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
                                 uint window, uint window_key, uint units_count,
                                 uint heads, uint layers, uint forecast,
                                 ENUM_OPTIMIZATION optimization_type, uint batch)
  {
//--- Init parent object
   if(!CNeuronBaseOCL::Init(numOutputs, myIndex, open_cl, window * forecast,
                                                   optimization_type, batch))
      return false;
```

Inside this method, we first invoke the initialization method of the base fully connected layer, which serves as the root parent class for all neural layers in our library. The parent class method provides the initialization of the basic interfaces of our object.

Two important points should be noted here: First, we call the base class initialization method, not the direct parent's. This is because the Market Observer's architecture significantly differs from that of its parent class.

Second, when invoking the parent initialization method, we specify the object size as the product of the planning horizon and the sequence element vector size. This matches the tensor we expect as the output of the Market Observer.

We then clear the dynamic array of pointers to internal objects:

```
//--- Clear layers' array
   cLayers.Clear();
   cLayers.SetOpenCL(OpenCL);
```

At this stage, the preparatory work is complete, and we can proceed to the actual construction of the Market Observer agent.

The model expects as input a multimodal time series represented as a sequence of vectors describing individual system states (in our case bars). To properly handle each univariate sequence, the incoming data must first be transposed.

```
//--- Tranpose input data
   int lay_count = 0;
   CNeuronTransposeOCL *transp = new CNeuronTransposeOCL();
   if(!transp ||
      !transp.Init(0, lay_count, OpenCL, units_count, window, optimization, iBatch) ||
      !cLayers.Add(transp))
     {
      delete transp;
      return false;
     }
```

Then we transform them into a piecewise-linear representation.

```
//--- Piecewise linear representation
   lay_count++;
   CNeuronPLROCL *plr = new CNeuronPLROCL();
   if(!plr ||
      !plr.Init(0, lay_count, OpenCL, units_count, window, false, optimization, iBatch) ||
      !cLayers.Add(plr))
     {
      delete plr;
      return false;
     }
```

To analyze dependencies between these univariate sequences, we use an attention module with relative positional encoding, parameterized with the required number of internal layers.

```
//--- Self-Attention for Variables
   lay_count++;
   CNeuronRMAT *att = new CNeuronRMAT();
   if(!att ||
      !att.Init(0, lay_count, OpenCL, units_count, window_key, window, heads, layers,
                                                                optimization, iBatch) ||
      !cLayers.Add(att))
     {
      delete att;
      return false;
     }
```

Based on the outputs of the attention block, we try to predict the upcoming values for each univariate sequence. Here, we use a residual convolutional block ( _CResidualConv_) as an _MLP_ substitute for independently predicting values of each univariate time series.

```
//--- Forecast mapping
   lay_count++;
   CResidualConv *conv = new CResidualConv();
   if(!conv ||
      !conv.Init(0, lay_count, OpenCL, units_count, forecast, window, optimization, iBatch) ||
      !cLayers.Add(conv))
     {
      delete conv;
      return false;
     }
```

Finally, the predicted results are transformed back into the dimensionality of the original input data.

```
//--- Back transpose forecast
   lay_count++;
   transp = new CNeuronTransposeOCL();
   if(!transp ||
      !transp.Init(0, lay_count, OpenCL, window, forecast, optimization, iBatch) ||
      !cLayers.Add(transp))
     {
      delete transp;
      return false;
     }
```

To minimize data-copying operations, we apply a pointer substitution technique with external interface buffers for efficient memory management.

```
   if(!SetOutput(transp.getOutput(), true) ||
      !SetGradient(transp.getGradient(), true))
      return false;
//---
   return true;
  }
```

The method then concludes by returning the boolean result of the operation to the caller.

The core functionality of this class is inherited from its parent object. Therefore, the Market Observer agent is now complete. The full source code of this class is provided in the attachment.

#### 2.2 RL Agent

The next step is building the _RL agent_. In the _MASA_ framework, this agent operates in parallel with the Market Observer, conducting independent market analysis and making decisions based on its learned policy.

The _MASA_ authors suggest implementing the _RL agent_ with a _[TD3-based model](https://www.mql5.com/en/articles/12892)_. However, we take a different architecture of the _RL agent_. For independent environment analysis, we use the _[PSformer](https://www.mql5.com/en/articles/16439)_ framework. Decision-making based on the performed analysis is handled by a lightweight perceptron enhanced with _SAM_ optimization.

Our _RL agent_ is implemented in a new object _CNeuronRLAgent_. Its structure is shown below.

```
class CNeuronRLAgent :  public   CNeuronRMAT
  {
public:
                     CNeuronRLAgent(void) {};
                    ~CNeuronRLAgent(void) {};
   //---
   virtual bool      Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
                          uint window, uint units_count, uint segments, float rho,
                          uint layers, uint n_actions,
                          ENUM_OPTIMIZATION optimization_type, uint batch);
   //---
   virtual int       Type(void)   const   override {  return defNeuronRLAgent;   }
  };
```

Similar to the Market Observer, we use here inheritance from _CNeuronRMAT_, a linear model base class. Thus, we just need to specify the new module's architecture within the _Init_ method.

```
bool CNeuronRLAgent::Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
                          uint window, uint units_count, uint segments,
                          float rho, uint layers, uint n_actions,
                          ENUM_OPTIMIZATION optimization_type, uint batch)
  {
//--- Init parent object
   if(!CNeuronBaseOCL::Init(numOutputs, myIndex, open_cl, n_actions, optimization_type, batch))
      return false;
```

The method parameters are very similar to those of the Market Observer. However, there are some differences. For example, the _forecast_ horizon parameter is replaced by the agent's action space ( _n\_actions_). Also, additional parameters include _segments_ (number of segments) and _rho_ (blurring coefficient).

Inside the Init method, we call the base fully connected layer initializer, specifying the action space of our _RL agent_ as the output tensor size.

We then clear the dynamic array of internal object pointers.

```
//--- Clear layers' array
   cLayers.Clear();
   cLayers.SetOpenCL(OpenCL);
```

The model's input data is first passed into the _PSformer_, whose required number of layers is created within a loop.

```
//--- State observation
   int lay_count = 0;
   for(uint i = 0; i < layers; i++)
    {
     CNeuronPSformer *psf = new CNeuronPSformer();
     if(!psf ||
        !psf.Init(0, lay_count, OpenCL, window, units_count, segments, rho, optimization,iBatch)||
        !cLayers.Add(psf))
       {
        delete psf;
        return false;
       }
     lay_count++;
    }
```

The _RL agent_ then makes decisions on the optimal action by feeding the outputs of the performed analysis into a decision block composed of convolutional and fully connected layers. The convolutional layer reduces dimensionality.

```
   CNeuronConvSAMOCL *conv = new CNeuronConvSAMOCL();
   if(!conv ||
      !conv.Init(n_actions, lay_count, OpenCL, window, window, 1, units_count,
                                                      1, optimization, iBatch) ||
      !cLayers.Add(conv))
     {
      delete conv;
      return false;
     }
   conv.SetActivationFunction(GELU);
   lay_count++;
```

The fully connected layer generates the action tensor.

```
   CNeuronBaseSAMOCL *flat = new CNeuronBaseSAMOCL();
   if(!flat ||
      !flat.Init(0, lay_count, OpenCL, n_actions, optimization, iBatch) ||
      !cLayers.Add(flat))
     {
      delete flat;
      return false;
     }
   SetActivationFunction(SIGMOID);
```

Note that in this case we do not use the Actor's stochastic policy. However, we may still need to use in the future, which we will discuss later.

By default, the action vector uses a sigmoid activation function, constraining values to the range between 0 and 1. This can be overridden by an external program if needed.

As before, we substitute pointers to data buffers of external interfaces, then return the Boolean result of initialization.

```
   if(!SetOutput(flat.getOutput(), true) ||
      !SetGradient(flat.getGradient(), true))
      return false;
//---
   return true;
  }
```

With this, the _RL agent_ object is complete. The full code of this class and all its methods can be found in the attachment.

#### 2.3 Controller

We have constructed objects of two agents out of three. We now turn to the third component: the _Controller_ Agent. Its role is to assess risk and adjust the _RL agent_'s actions based on the environment state analysis performed by the Market Observer.

The key distinction here is that the Controller processes two input data sources. It must evaluate not only each input individually but also their interdependencies. In my opinion, the _Transformer_ decoder structure perfectly suits this task. Instead of standard _Self-Attention_ and _Cross-Attention_ modules, however, we use relative positional encoding variants.

The Controller is implemented as a new object _CNeuronControlAgent_ again inheriting from _CNeuronRMAT_. Since it works with dual input streams, several methods require redefinition. The structure of the new class is shown below.

```
class CNeuronControlAgent  :  public CNeuronRMAT
  {
protected:
   virtual bool      feedForward(CNeuronBaseOCL *NeuronOCL) override { return false; }
   virtual bool      feedForward(CNeuronBaseOCL *NeuronOCL,
                                 CBufferFloat *SecondInput) override;
   virtual bool      calcInputGradients(CNeuronBaseOCL *NeuronOCL) override { return false; }
   virtual bool      calcInputGradients(CNeuronBaseOCL *NeuronOCL,
                                        CBufferFloat *SecondInput,
                                        CBufferFloat *SecondGradient,
                                        ENUM_ACTIVATION SecondActivation = None) override;
   virtual bool      updateInputWeights(CNeuronBaseOCL *NeuronOCL) override { return false; }
   virtual bool      updateInputWeights(CNeuronBaseOCL *NeuronOCL,
                                        CBufferFloat *SecondInput) override;

public:
                     CNeuronControlAgent(void) {};
                    ~CNeuronControlAgent(void) {};
   //---
   virtual bool      Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
                          uint window, uint window_key, uint units_count, uint heads,
                          uint window_kv, uint units_kv, uint layers,
                          ENUM_OPTIMIZATION optimization_type, uint batch);
   //---
   virtual int       Type(void) override   const   {  return defNeuronControlAgent; }
  };
```

Again, initialization of internal objects is performed in the _Init_ method, which specifies the _Transformer_ decoder architecture.

```
bool CNeuronControlAgent::Init(uint numOutputs, uint myIndex, COpenCLMy *open_cl,
                               uint window, uint window_key, uint units_count,
                               uint heads, uint window_kv, uint units_kv, uint layers,
                               ENUM_OPTIMIZATION optimization_type, uint batch)
  {
//--- Init parent object
   if(!CNeuronBaseOCL::Init(numOutputs, myIndex, open_cl, window * units_count,
                                                     optimization_type, batch))
      return false;
//--- Clear layers' array
   cLayers.Clear();
   cLayers.SetOpenCL(OpenCL);
```

As in previous cases, we call the relevant method of the base fully connected layer, specifying the dimensionality of the outputs at the level of the main input tensor. After that, we clear the dynamic array of pointers.

Next, we proceed to construct the architecture of our Controller Agent. Recall that the Market Observer outputs a multimodal time series, a sequence of vectors representing predicted states of the environment (bars).

Two approaches are possible: aligning _RL agent_ actions with individual bars, or with univariate sequences. We understand that the Market Observer provided us with only forecast data, the probability of which being realized is far from 100%. Also, there is a possibility of deviations in absolutely all values.

Let's think logically. How much information can the vector describing one forecast candlestick give us, provided that each element can cave varying deviations? The question is controversial and difficult to answer without understanding the accuracy of individual forecasts.

On the other hand, if you look at a separate univariate series, then, in addition to individual values, you can also identify the trend of the upcoming movement. Since the trend is formed by a set of values, we could logically expect the confirmation of a trend, even if some elements deviate.

Moreover, all univariate sequences in our multimodal time series have certain interdependencies. So, when the predicted trend of one univariate time series is confirmed by the values of another, the probability of such a forecast increases.

Taking this into account, we decided to analyze the dependence of the agent's actions on the predicted values of univariate sequences. Accordingly, we first feed the secondary data source into a prepared neural layer.

```
   int lay_count = 0;
   CNeuronBaseOCL *flat = new CNeuronBaseOCL();
   if(!flat ||
      !flat.Init(0, lay_count, OpenCL, window_kv * units_kv, optimization, iBatch) ||
      !cLayers.Add(flat))
     {
      delete flat;
      return false;
     }
```

And then we reformat it into univariate sequence representations.

```
   lay_count++;
   CNeuronTransposeOCL *transp = new CNeuronTransposeOCL();
   if(!transp ||
      !transp.Init(0, lay_count, OpenCL, units_kv, window_kv, optimization, iBatch) ||
      !cLayers.Add(transp))
     {
      delete transp;
      return false;
     }
   lay_count++;
```

Next, we need to construct the architecture of our decoder. The required number of layers is created in a loop. The number of iterations is determined by the external parameters of the initialization method.

```
//--- Attention Action To Observation
   for(uint i = 0; i < layers; i++)
     {
      if(units_count > 1)
        {
         CNeuronRelativeSelfAttention *self = new CNeuronRelativeSelfAttention();
         if(!self ||
            !self.Init(0, lay_count, OpenCL, window, window_key, units_count, heads,
                                                               optimization, iBatch) ||
            !cLayers.Add(self))
           {
            delete self;
            return false;
           }
         lay_count++;
        }
```

It is important to note that, in the vanilla _Transformer_ decoder, input data is first processed by a _Self-Attention_ module, which analyzes dependencies between individual elements of the source sequence. In our implementation, we replace this module with its counterpart that uses relative positional encoding. However, we only create this module if the source sequence contains more than one element. Because, clearly, with only a single element, there are no dependencies to analyze. In this case, the _Self-Attention_ module would be redundant.

Next, we create a Cross-Attention module, which analyzes dependencies between elements of the two data sources.

```
      CNeuronRelativeCrossAttention *cross = new CNeuronRelativeCrossAttention();
      if(!cross ||
         !cross.Init(0, lay_count, OpenCL, window, window_key, units_count, heads,
                                        units_kv, window_kv, optimization, iBatch) ||
         !cLayers.Add(cross))
        {
         delete cross;
         return false;
        }
      lay_count++;
```

Each decoder layer is then completed with a _FeedForward_ block, for which we use a residual convolutional block.

```
      CResidualConv *ffn = new CResidualConv();
      if(!ffn ||
         !ffn.Init(0, lay_count, OpenCL, window, window, units_count, optimization, iBatch) ||
         !cLayers.Add(ffn))
        {
         delete ffn;
         return false;
        }
      lay_count++;
     }
```

After this, we proceed to the next loop iteration and construct the following decoder layer.

As in the standard _Transformer_ decoder architecture, the output of the residual convolutional block undergoes normalization. However, we may also need to constrain the Actor's action space to a defined range, which is typically handled by an activation function. Therefore, after constructing the required number of decoder layers, we add an additional convolutional layer with the specified activation function.

```
   CNeuronConvSAMOCL *conv = new CNeuronConvSAMOCL();
   if(!conv ||
      !conv.Init(0, lay_count, OpenCL, window, window, window, units_count, 1,
                                                       optimization, iBatch) ||
      !cLayers.Add(conv))
     {
      delete conv;
      return false;
     }
   SetActivationFunction(SIGMOID);
```

By default, as with the _RL agent_, we use the sigmoid function. However, we keep the option to override it from an external program.

Finally, at the end of the initialization method, we substitute pointers to the interface buffers and return a Boolean value to the calling program, indicating the success of the operation.

```
//---
   if(!SetOutput(conv.getOutput(), true) ||
      !SetGradient(conv.getGradient(), true))
      return false;
//---
   return true;
  }
```

After completing the initialization of the new object, we move on to constructing feed-forward algorithm in the _feedForward_ method.

```
bool CNeuronControlAgent::feedForward(CNeuronBaseOCL *NeuronOCL, CBufferFloat *SecondInput)
  {
   if(!SecondInput)
      return false;
```

In the method parameters, we receive pointers to two input data objects. The primary data stream is passed as a neural layer, and the secondary data stream is provided as a data buffer. For ease of use, we substitute the buffer of results of a specially created internal layer with the object received in the method parameters.

```
   CNeuronBaseOCL *second = cLayers[0];
   if(!second)
      return false;
   if(!second.SetOutput(SecondInput, true))
      return false;
```

We then transpose the tensor of the secondary data source to represent the multimodal time series as a sequence of univariate series.

```
   second = cLayers[1];
   if(!second || !second.FeedForward(cLayers[0]))
      return false;
```

Next, we iterate through the remaining internal neural layers in sequence, calling their feed-forward methods and passing them both data sources.

```
   CNeuronBaseOCL *first = NeuronOCL;
   CNeuronBaseOCL *main = NULL;
   for(int i = 2; i < cLayers.Total(); i++)
     {
      main = cLayers[i];
      if(!main ||
         !main.FeedForward(first, second.getOutput()))
         return false;
      first = main;
     }
//---
   return true;
  }
```

After successfully completing all loop iterations, we simply return a Boolean result to the caller, signaling successful execution.

As can be seen, the feed-forward algorithm is relatively straightforward. This is thanks to the use of prebuilt blocks to construct a more complex architecture.

The situation becomes more challenging when implementing the error gradient distribution algorithm, due to the use of a secondary data source. Along the primary data path, information is passed sequentially from one internal layer to the next. However, the secondary data source is shared across all decoder layers. Specifically across all Cross-Attention modules. Consequently, the error gradient for the secondary data must be collected from all Cross-Attention modules. I suggest looking at the solution to this issue in code.

This logic is implemented in the _calcInputGradients_ method. The method parameters include pointers to the two input data streams and their corresponding error gradients. Our task is to distribute the error gradient between the two data sources according to their contribution to the final output.

```
bool CNeuronControlAgent::calcInputGradients(CNeuronBaseOCL *NeuronOCL, CBufferFloat *SecondInput,
                              CBufferFloat *SecondGradient, ENUM_ACTIVATION SecondActivation = -1)
  {
   if(!NeuronOCL || !SecondGradient)
      return false;
```

Inside the method, we first validate the received pointers, since we cannot pass data to non-existent objects.

As with the forward pass, the secondary data source is represented as buffers. And we substitute the pointers in the corresponding internal layer.

```
   CNeuronBaseOCL *main = cLayers[0];
   if(!main)
      return false;
   if(!main.SetGradient(SecondGradient, true))
      return false;
   main.SetActivationFunction(SecondActivation);
//---
   CNeuronBaseOCL *second = cLayers[1];
   if(!second)
      return false;
   second.SetActivationFunction(SecondActivation);
```

At this stage, we also synchronize the activation functions of the internal layer and the subsequent transposition layer with the activation function of the input data. This ensures correct gradient propagation.

The transposition layer now acts as the secondary data source. For convenience, we store pointers to its interface objects in local variables.

```
   CBufferFloat *second_out = second.getOutput();
   CBufferFloat *second_gr = second.getGradient();
   CBufferFloat *temp = second.getPrevOutput();
   if(!second_gr.Fill(0))
      return false;
```

And we clear its gradient buffer of any previously accumulated values.

We then iterate backward through the internal neural layers. Note that within this loop we only work with decoder objects.

Since the first two internal objects are reserved for handling the secondary data source.

```
   for(int i = cLayers.Total() - 2; i >= 2; i--)
     {
      main = cLayers[i];
      if(!main)
         return false;
```

For each decoder layer, we retrieve its pointer from the array and validate it.

Because not all decoder modules operate with two data sources, the algorithm branches depending on the object type. For Cross-Attention modules, we first pass the error gradient of the secondary data source from the current layer into a temporary storage buffer, then accumulate these values with previously stored results.

```
      if(cLayers[i + 1].Type() == defNeuronRelativeCrossAttention)
        {
         if(!main.calcHiddenGradients(cLayers[i + 1], second_out, temp, SecondActivation) ||
            !SumAndNormilize(temp, second_gr, second_gr, 1, false, 0, 0, 0, 1))
            return false;
        }
```

For other modules, we simply propagate the error gradient along the primary path. And then we move on to the next iteration of the loop.

```
      else
        {
         if(!main.calcHiddenGradients(cLayers[i + 1]))
            return false;
        }
     }
```

After completing all iterations, we propagate the accumulated gradients back to the input data sources. First, we pass the gradient along the primary path to the first data source.

```
   if(!NeuronOCL.calcHiddenGradients(main.AsObject(), second_out, temp, SecondActivation))
      return false;
```

However, recall that the first decoder layer may be either a _Self-Attention_ or _Cross-Attention_ module. In the latter case, both data sources are used. So, we must check the object type and, if necessary, add the accumulated gradient of the second data source.

```
   if(main.Type() == defNeuronRelativeCrossAttention)
     {
      if(!SumAndNormilize(temp, second_gr, second_gr, 1, false, 0, 0, 0, 1))
         return false;
     }
```

Finally, we pass the complete accumulated gradient along the secondary path to the corresponding input source.

```
   main = cLayers[0];
   if(!main.calcHiddenGradients(second.AsObject()))
      return false;
//---
   return true;
  }
```

The method ends by returning a logical result to the calling program.

The parameter update algorithm, implemented in the _updateInputWeights_ method, is relatively simple. We loop through the internal objects containing trainable parameters, calling their corresponding update methods. We will not go into detail here. But it is important to note that the constructed object architecture uses modules with _SAM_-optimized parameters. Therefore, the iteration through internal objects must be performed in reverse order.

With this, we conclude our discussion of the algorithms used to implement the Controller agent's methods. The complete code for the new class and all its methods is provided in the attachments.

We have made substantial progress today, though our work is not yet finished. We will take a short break, and in the next article, we will bring the project to its logical conclusion.

### Conclusion

We have examined an innovative approach to portfolio management under volatile financial market conditions – the Multi-Agent Self-Adaptive ( _MASA_) framework. The proposed framework successfully combines the advantages of _RL_ algorithms for return optimization, adaptive optimization methods for risk minimization, and a Market Observer module for trend analysis.

In the practical section, we implemented each of the proposed agents in _MQL5_ as standalone modules. In the next article, we will integrate them into a complete system and evaluate the performance of the implemented solutions using real historical data.

#### References

- [Developing A Multi-Agent and Self-Adaptive Framework with Deep Reinforcement Learning for Dynamic Portfolio Risk Management](https://www.mql5.com/go?link=https://arxiv.org/abs/2402.00515 "Developing A Multi-Agent and Self-Adaptive Framework with Deep Reinforcement Learning for Dynamic Portfolio Risk Management")
- [Other articles from this series](https://www.mql5.com/en/search#!keyword=Neural%20networks%20made%20easy&module=mql5_module_articles "https://www.mql5.com/en/search#!keyword=Neural%20networks%20made%20easy&module=mql5_module_articles")

#### Programs used in the article

| # | Name | Type | Description |
| --- | --- | --- | --- |
| 1 | Research.mq5 | Expert Advisor | Expert Advisor for collecting examples |
| 2 | ResearchRealORL.mq5 | Expert Advisor | Expert Advisor for collecting examples using the Real-ORL method |
| 3 | Study.mq5 | Expert Advisor | Model training Expert Advisor |
| 4 | Test.mq5 | Expert Advisor | Model testing Expert Advisor |
| 5 | Trajectory.mqh | Class library | System state description structure |
| 6 | NeuroNet.mqh | Class library | A library of classes for creating a neural network |
| 7 | NeuroNet.cl | Library | OpenCL program code library |

Translated from Russian by MetaQuotes Ltd.

Original article: [https://www.mql5.com/ru/articles/16537](https://www.mql5.com/ru/articles/16537)

**Attached files** \|


[Download ZIP](https://www.mql5.com/en/articles/download/16537.zip "Download all attachments in the single ZIP archive")

[MQL5.zip](https://www.mql5.com/en/articles/download/16537/mql5.zip "Download MQL5.zip")(2195.85 KB)

**Warning:** All rights to these materials are reserved by MetaQuotes Ltd. Copying or reprinting of these materials in whole or in part is prohibited.

This article was written by a user of the site and reflects their personal views. MetaQuotes Ltd is not responsible for the accuracy of the information presented, nor for any consequences resulting from the use of the solutions, strategies or recommendations described.

#### Other articles by this author

- [Neural Networks in Trading: Hybrid Graph Sequence Models (GSM++)](https://www.mql5.com/en/articles/17279)
- [Neural Networks in Trading: Two-Dimensional Connection Space Models (Final Part)](https://www.mql5.com/en/articles/17241)
- [Neural Networks in Trading: Two-Dimensional Connection Space Models (Chimera)](https://www.mql5.com/en/articles/17210)
- [Neural Networks in Trading: Multi-Task Learning Based on the ResNeXt Model (Final Part)](https://www.mql5.com/en/articles/17157)
- [Neural Networks in Trading: Multi-Task Learning Based on the ResNeXt Model](https://www.mql5.com/en/articles/17142)
- [Neural Networks in Trading: Hierarchical Dual-Tower Transformer (Final Part)](https://www.mql5.com/en/articles/17104)
- [Neural Networks in Trading: Hierarchical Dual-Tower Transformer (Hidformer)](https://www.mql5.com/en/articles/17069)

**[Go to discussion](https://www.mql5.com/en/forum/494060)**

![Analyzing binary code of prices on the exchange (Part II): Converting to BIP39 and writing GPT model](https://c.mql5.com/2/118/Analyzing_the_Binary_Code_of_Stock_Exchange_Prices_Part_II___LOGO.png)[Analyzing binary code of prices on the exchange (Part II): Converting to BIP39 and writing GPT model](https://www.mql5.com/en/articles/17110)

Continuing tries to decipher price movements... What about linguistic analysis of the "market dictionary" that we get by converting the binary price code to BIP39? In this article, we will delve into an innovative approach to exchange data analysis and consider how modern natural language processing techniques can be applied to the market language.

![Artificial Tribe Algorithm (ATA)](https://c.mql5.com/2/106/Artificial_Tribe_Algorithm_LOGO.png)[Artificial Tribe Algorithm (ATA)](https://www.mql5.com/en/articles/16588)

The article provides a detailed discussion of the key components and innovations of the ATA optimization algorithm, which is an evolutionary method with a unique dual behavior system that adapts depending on the situation. ATA combines individual and social learning while using crossover for explorations and migration to find solutions when stuck in local optima.

![Automating Trading Strategies in MQL5 (Part 28): Creating a Price Action Bat Harmonic Pattern with Visual Feedback](https://c.mql5.com/2/165/19105-automating-trading-strategies-logo.png)[Automating Trading Strategies in MQL5 (Part 28): Creating a Price Action Bat Harmonic Pattern with Visual Feedback](https://www.mql5.com/en/articles/19105)

In this article, we develop a Bat Pattern system in MQL5 that identifies bullish and bearish Bat harmonic patterns using pivot points and Fibonacci ratios, triggering trades with precise entry, stop loss, and take-profit levels, enhanced with visual feedback through chart objects

![Analyzing binary code of prices on the exchange (Part I): A new look at technical analysis](https://c.mql5.com/2/110/Analyzing_the_Binary_Code_of_Stock_Exchange_Prices_Part_I____LOGO.png)[Analyzing binary code of prices on the exchange (Part I): A new look at technical analysis](https://www.mql5.com/en/articles/16741)

This article presents an innovative approach to technical analysis based on converting price movements into binary code. The author demonstrates how various aspects of market behavior — from simple price movements to complex patterns — can be encoded in a sequence of zeros and ones.

[![](https://www.mql5.com/ff/sh/x8fwvn495ta7y774z2/01.png)Does your broker offer sponsored hosting for trading?Now it's even easier to get MetaTrader VPS for free – contact your broker for details](https://www.mql5.com/ff/go?link=https://www.mql5.com/en/forum/449311&a=xscnzeyhifcgygpwvysykhqydcmmbgpp&s=f87b748147e376d34c8f0fdb9737b1766f20cc2174769a0e6b9975b5c2e8ddae&uid=&ref=https://www.mql5.com/en/articles/16537&id=wdausxxqrpvhekbwjrjlhqjghyhesrqqau&fz_uniq=5069534153914910366)

This website uses cookies. Learn more about our [Cookies Policy](https://www.mql5.com/en/about/cookies).

![close](https://c.mql5.com/i/close.png)

![MQL5 - Language of trade strategies built-in the MetaTrader 5 client terminal](https://c.mql5.com/i/registerlandings/logo-2.png)

You are missing trading opportunities:

- Free trading apps
- Over 8,000 signals for copying
- Economic news for exploring financial markets

RegistrationLog in

latin characters without spaces

a password will be sent to this email

An error occurred


- [Log in With Google](https://www.mql5.com/en/auth_oauth2?provider=Google&amp;return=popup&amp;reg=1)

You agree to [website policy](https://www.mql5.com/en/about/privacy) and [terms of use](https://www.mql5.com/en/about/terms)

If you do not have an account, please [register](https://www.mql5.com/en/auth_register)

Allow the use of cookies to log in to the MQL5.com website.

Please enable the necessary setting in your browser, otherwise you will not be able to log in.

[Forgot your login/password?](https://www.mql5.com/en/auth_forgotten?return=popup)

- [Log in With Google](https://www.mql5.com/en/auth_oauth2?provider=Google&amp;return=popup)